-- Fluid Language Server Protocol (LSP) Server Library
--
-- Provides a TCP-based LSP server for IDE integration with Fluid scripts.
-- Implements the JSON-RPC 2.0 protocol with LSP wire format (Content-Length framing).
--
-- The server supports handler registration for extending LSP functionality:
--    server.registerHandler('textDocument/hover', function(msg, state) ... end)

   include 'network'
   json = require('json')
   require 'common'
   require 'io/filesearch'

   CACHE_PATH = 'user:config/lsp_doc_cache.fluid'

   self = { }

   glTime = obj.new('time')
   glSelf = obj.find('self')

   -- Document storage for open files.  URI indexed
   glDocuments = { }

   -- Documentation cache and static definitions for hover
   glDocCache = nil
   glDefs = nil

   -- Token cache for delta semantic tokens.  URI indexed
   -- Structure: { [uri] = { resultId = number, data = { ... } } }
   glTokenCache = { }
   glNextResultId = 1

----------------------------------------------------------------------------------------------------------------------
-- Document Line Index
-- Lazily computes and caches an array of line byte offsets. Invalidate by setting doc.lineIndex = nil on changes.
-- Format: array<int> with pairs of (start, stop) for each line, so line N is at indices N*2 and N*2+1.

function rebuildLineIndex(Doc:table, FromLine:num)
   if Doc.lineIndex then return end

   content = Doc.content
   len = #content
   pos = 0

   if not FromLine or not Doc.lineIndex or FromLine is 0 then
      -- Full rebuild
      Doc.lineIndex = array<int>
   else
      -- Incremental rebuild from FromLine onwards
      -- Truncate the array to keep lines 0..FromLine-1
      keep_count = FromLine * 2
      if keep_count > #Doc.lineIndex then
         keep_count = #Doc.lineIndex
      end

      -- Remove entries from FromLine onwards
      Doc.lineIndex:resize(keep_count)

      -- Start scanning from where FromLine begins
      if keep_count >= 2 then
         -- Position after the previous line's newline
         pos = Doc.lineIndex[keep_count - 1] + 1  -- After stop of previous line + newline
         if pos > len then pos = len end
      else
         pos = 0
      end
   end

   while pos < len do
      -- Find end of line (newline or end of content)
      newline_pos = content:find('\n', pos)
      if newline_pos then
         Doc.lineIndex:push(pos, newline_pos - 1)
         pos = newline_pos + 1  -- Skip past the newline
      else
         Doc.lineIndex:push(pos, len - 1)
         break
      end
   end

   -- Handle empty document or trailing newline
   if #Doc.lineIndex is 0 or (len > 0 and content:sub(len - 1, len) is '\n') then
      Doc.lineIndex:push(len, len)  -- start, stop
   end
end

function getTotalLines(Doc:table):num
   rebuildLineIndex(Doc)
   return #Doc.lineIndex / 2
end

function getLine(Doc:table, LineNo:num):str
   rebuildLineIndex(Doc)
   total_lines = #Doc.lineIndex / 2
   if LineNo < 0 or LineNo >= total_lines then return '' end

   idx = LineNo * 2
   return Doc.content:sub(Doc.lineIndex[idx], Doc.lineIndex[idx + 1])
end

-- Mark line N and subsequent lines for recomputation.  Currently we are very lazy about this...

function markLineIndex(Doc:table, LineNo:num)
   Doc.lineIndex = nil
end

----------------------------------------------------------------------------------------------------------------------
-- Semantic Token Types and Modifiers (LSP standard)

-- Token types - order matters, index is used in the protocol

TOKEN_TYPES = array<string> {
   'keyword',        -- 0: if, while, for, etc.
   'operator',       -- 1: and, or, not, is
   'variable',       -- 2: regular variables
   'function',       -- 3: function names
   'string',         -- 4: string literals
   'number',         -- 5: numeric literals
   'comment',        -- 6: comments
   'type',           -- 7: type names
   'parameter',      -- 8: function parameters
   'property',       -- 9: object properties
   'namespace',      -- 10: module/namespace
   'class',          -- 11: class names
   'macro'           -- 12: constants like ERR_Okay
}

-- Token modifiers (bitfield)
TOKEN_MODIFIERS = array<string> {
   'declaration',    -- 0: variable/function declaration
   'definition',     -- 1: definition site
   'readonly',       -- 2: constants
   'static',         -- 3: static members
   'deprecated',     -- 4: deprecated items
   'modification',   -- 5: modified variable
   'documentation',  -- 6: documentation strings
   'defaultLibrary'  -- 7: built-in functions
}

-- Fluid reserved keywords
FLUID_KEYWORDS = {
   -- Control flow
   ['if'] = true, ['then'] = true, ['else'] = true, ['elseif'] = true,
   ['for'] = true, ['in'] = true, ['while'] = true, ['do'] = true,
   ['repeat'] = true, ['until'] = true, ['break'] = true, ['continue'] = true,
   ['return'] = true, ['end'] = true,

   -- Pattern matching
   ['choose'] = true, ['from'] = true, ['when'] = true,

   -- Declarations
   ['function'] = true, ['local'] = true, ['global'] = true, ['thunk'] = true,

   -- Special
   ['defer'] = true, ['catch'] = true, ['raise'] = true, ['check'] = true
}

-- Logical/comparison operators (highlighted as operators)
FLUID_OPERATORS = {
   ['and'] = true, ['or'] = true, ['not'] = true, ['is'] = true
}

-- Built-in constants
FLUID_CONSTANTS = {
   ['true'] = true, ['false'] = true, ['nil'] = true
}

-- Built-in functions (default library)
FLUID_BUILTINS = {
   -- Output
   ['print'] = true, ['msg'] = true, ['error'] = true, ['assert'] = true,

   -- Type conversion/introspection
   ['type'] = true, ['tonumber'] = true, ['tostring'] = true,

   -- Iteration
   ['pairs'] = true, ['ipairs'] = true, ['next'] = true, ['values'] = true,

   -- Result handling
   ['unpack'] = true,

   -- Protected calls
   ['pcall'] = true, ['xpcall'] = true,

   -- Metatable access
   ['setmetatable'] = true, ['getmetatable'] = true,
   ['rawget'] = true, ['rawset'] = true, ['rawequal'] = true,

   -- Script/module loading
   ['collectgarbage'] = true, ['require'] = true, ['include'] = true,
   ['loadFile'] = true, ['load'] = true, ['exec'] = true,

   -- Script parameters
   ['arg'] = true,

   -- Deferred expressions
   ['resolve'] = true,

   -- Range constructor
   ['range'] = true,

   -- Events
   ['subscribeEvent'] = true, ['unsubscribeEvent'] = true,

   -- Structures
   ['MAKESTRUCT'] = true
}

-- Parasol modules/namespaces
FLUID_MODULES = {
   -- Core interfaces
   ['obj'] = true, ['struct'] = true, ['array'] = true, ['regex'] = true,
   ['mod'] = true, ['thread'] = true, ['processing'] = true,

   -- Parasol API modules (loaded via mod.load())
   ['mSys'] = true, ['mVec'] = true, ['mGfx'] = true,
   ['mAudio'] = true, ['mFont'] = true, ['mNet'] = true, ['mXML'] = true,

   -- Standard libraries
   ['string'] = true, ['table'] = true, ['math'] = true, ['bit'] = true,
   ['io'] = true, ['debug'] = true,

   -- Fluid script libraries
   ['json'] = true, ['gui'] = true, ['file'] = true
}

----------------------------------------------------------------------------------------------------------------------
-- Utility Functions

function timestamp():str
   glTime.acQuery()
   return string.format('%04d-%02d-%02d %02d:%02d:%02d',
      glTime.year, glTime.month, glTime.day, glTime.hour, glTime.minute, glTime.second)
end

function logMessage(Self:table, Message:str)
   Self?.logMessage('[' .. timestamp() .. '] ' .. Message)
end

function logVerbose(Self:table, Message:str)
   if Self.verbose then
      Self?.logMessage('[' .. timestamp() .. '] [DEBUG] ' .. Message)
   end
end

function logWarning(Self:table, Message:str)
   Self?.logMessage('[' .. timestamp() .. '] [WARN] ' .. Message)
end

----------------------------------------------------------------------------------------------------------------------
-- LSP Wire Protocol Parsing

-- Parse the Content-Length header from the buffer
-- Returns: content_length, body_start_offset, error_message
-- If incomplete (need more data): nil, nil, nil
-- If error: nil, nil, error_string
-- If success: content_length, body_start_offset, nil

function parseHeader(Buffer:str):<str,num,str>
   header_end = Buffer:find('\r\n\r\n')
   header_end ?? return nil, nil, nil  -- Need more data
   header_section = Buffer:sub(0, header_end)
   content_length = nil

   for line in header_section:gmatch('[^\r\n]+') do
      name, value = line:match('([^:]+):%s*(.+)')
      if name and name:lower() is 'content-length' then
         content_length = tonumber(value)
         break
      end
   end

   content_length ?? return nil, nil, 'Missing Content-Length header'
   return content_length, header_end + 4, nil  -- +4 for \r\n\r\n
end

----------------------------------------------------------------------------------------------------------------------
-- Parse a JSON-RPC 2.0 message

function parseMessage(JsonBody)
   local success, msg = pcall(function()
      return json.decode(JsonBody)
   end)

   success ?? return nil, 'JSON parse error: ' .. tostring(msg)

   if msg.jsonrpc != '2.0' then
      return nil, 'Invalid JSON-RPC version: ' .. tostring(msg.jsonrpc)
   end

   return msg, nil
end

----------------------------------------------------------------------------------------------------------------------
-- Response Formatting

function formatResponse(ResponseTable:table):str
   body = json.encode(ResponseTable)
   return 'Content-Length: ' .. #body .. '\r\n\r\n' .. body
end

function sendResponse(Self, ClientSocket, ResponseTable, RequestLog)
   ResponseTable ?? return -- Notifications don't get responses

   formatted = formatResponse(ResponseTable)
   err = ClientSocket.acWrite(formatted)
   if err != ERR_Okay then
      logMessage(Self, 'Failed to send response: ' .. mSys.GetErrorMsg(err))
   else
      logVerbose(Self, 'Sent response: ' .. formatted:sub(0, 200))

      -- Log outgoing response if logging enabled
      if RequestLog then
         RequestLog('RESPONSE', formatted)
      end
   end
end

----------------------------------------------------------------------------------------------------------------------
-- Send an LSP notification (no response expected)

function sendNotification(Self, ClientSocket, Method, Params)
   notification = {
      jsonrpc = '2.0',
      method = Method,
      params = Params
   }
   formatted = formatResponse(notification)
   err = ClientSocket.acWrite(formatted)
   if err != ERR_Okay then
      logMessage(Self, 'Failed to send notification: ' .. mSys.GetErrorMsg(err))
   else
      logVerbose(Self, 'Sent notification: ' .. Method)
   end
end

----------------------------------------------------------------------------------------------------------------------
-- Compute diagnostics for a document using debug.validate()

-- Helper to check if character is alphanumeric or underscore

function isIdentChar(C)
   return (C >= 'a' and C <= 'z') or (C >= 'A' and C <= 'Z') or (C >= '0' and C <= '9') or C is '_'
end

-- Compute start and end columns for an error range based on context
-- Returns: start_col, end_col

function computeErrorRange(Doc:table, Line:num, Column:num)
   -- Find the target line
   if Line >= getTotalLines(Doc) then return Column, Column + 1 end

   line_text = getLine(Doc, Line)
   if Column >= #line_text then return Column, Column + 1 end

   c = line_text:sub(Column, Column + 1)

   -- If starting on an identifier/number character, extend both directions
   if isIdentChar(c) or (c >= '0' and c <= '9') then
      -- Extend backwards to find start of token

      start_col = Column
      while start_col > 0 do
         prev_c = line_text:sub(start_col - 1, start_col)
         if isIdentChar(prev_c) or (prev_c >= '0' and prev_c <= '9') then
            start_col -= 1
         else
            break
         end
      end

      -- Extend forwards to find end of token

      end_col = Column + 1
      while end_col < #line_text do
         next_c = line_text:sub(end_col, end_col + 1)
         if isIdentChar(next_c) or (next_c >= '0' and next_c <= '9') then
            end_col++
         else
            break
         end
      end
      return start_col, end_col
   end

   -- For operators and punctuation, try to capture multi-character operators

   if c is '=' or c is '!' or c is '<' or c is '>' or c is '~' or c is ':' or c is '.' then
      next_c = (Column + 1 < #line_text) and line_text:sub(Column + 1, Column + 2) or ''
      if next_c is '=' or next_c is '>' then
         return Column, Column + 2
      end
   end

   -- For string delimiters, try to find matching end

   if c is '"' or c is "'" then
      end_col = Column + 1
      while end_col < #line_text do
         sc = line_text:sub(end_col, end_col + 1)
         if sc is c then
            return Column, end_col + 1
         elseif sc is '\\' then
            end_col += 2  -- Skip escaped character
         else
            end_col++
         end
      end
      return Column, #line_text  -- Unterminated string - highlight to end of line
   end

   -- Default: single character
   return Column, Column + 1
end

function computeDiagnostics(Doc:table)
   result = debug.validate(Doc.content)

   lsp_diags = array<table>

   if result.diagnostics then
      rebuildLineIndex(Doc)

      for diag in values(result.diagnostics) do
         -- Map severity: C++ (0=Info,1=Warn,2=Error) -> LSP (1=Error,2=Warn,3=Info)
         lsp_severity = 3  -- Default to Info
         if diag.severity is 2 then lsp_severity = 1      -- Error
         elseif diag.severity is 1 then lsp_severity = 2  -- Warning
         end

         -- Compute a meaningful range if not provided by the parser
         start_col = diag.column
         end_col = diag.endColumn
         if end_col <= start_col+1 then
            start_col, end_col = computeErrorRange(Doc, diag.line, diag.column)
         end

         lsp_diags:push({
            range = {
               start = { line = diag.line, character = start_col },
               ['end'] = { line = diag.line, character = end_col }
            },
            severity = lsp_severity,
            source = 'fluid',
            code = diag.code,
            message = diag.message
         })
      end
   end

   -- Add tips as LSP Hint diagnostics (severity 4)
   if result.tips then
      for tip in values(result.tips) do
         start_col = tip.column
         end_col = tip.endColumn
         if end_col <= start_col+1 then
            start_col, end_col = computeErrorRange(Doc, tip.line, tip.column)
         end

         lsp_diags:push({
            range = {
               start = { line = tip.line, character = start_col },
               ['end'] = { line = tip.line, character = end_col }
            },
            severity = 4,  -- LSP Hint
            source = 'fluid',
            code = tip.category,
            message = tip.message
         })
      end
   end

   return { uri = Doc.uri, version = Doc.version, diagnostics = lsp_diags }
end

----------------------------------------------------------------------------------------------------------------------
-- Text Edit Helper

-- Convert line/character position to byte offset in document
function positionToOffset(Content, Line, Character)
   offset = 0
   current_line = 0

   while current_line < Line and offset < #Content do
      c = Content:sub(offset, offset + 1)
      if c is '\n' then
         current_line++
      end
      offset++
   end

   -- Add character offset within the line
   return offset + Character
end

-- Apply a text edit to document content
function applyTextEdit(Content, Range, NewText)
   start_offset = positionToOffset(Content, Range.start.line, Range.start.character)
   end_offset = positionToOffset(Content, Range['end'].line, Range['end'].character)

   -- Build new content: before + new text + after
   before = Content:sub(0, start_offset)
   after = Content:sub(end_offset)

   return before .. NewText .. after
end

----------------------------------------------------------------------------------------------------------------------
-- LSP Error Codes

LSP_ERROR = {
   PARSE_ERROR      = -32700,
   INVALID_REQUEST  = -32600,
   METHOD_NOT_FOUND = -32601,
   INVALID_PARAMS   = -32602,
   INTERNAL_ERROR   = -32603
}

function makeErrorResponse(Id:num, Code:num, Message:str):table
   return {
      jsonrpc = '2.0',
      id = Id,
      error = {
         code = Code,
         message = Message
      }
   }
end

----------------------------------------------------------------------------------------------------------------------
-- Semantic Token Encoder

-- Tokenize a Fluid source file and return semantic tokens
-- Returns array of tokens: { line, startChar, length, tokenType, tokenModifiers }

function tokenizeFluid(Source:str):array
   tokens = array<table>
   line = 0
   col = 0
   pos = 0
   len = #Source

   -- Helper to add a token (skips zero-length tokens)
   function addToken(TokenLine, TokenCol, TokenLen, TokenType, TokenMod)
      if TokenLen <= 0 then return end  -- Skip invalid tokens
      tokens:push({
         line   = TokenLine,
         char   = TokenCol,
         length = TokenLen,
         type   = TokenType,
         modifiers = TokenMod or 0
      })
   end

   -- Skip whitespace and track position
   function skipWhitespace()
      while pos < len do
         c = Source:sub(pos, pos + 1)
         if c is ' ' or c is '\t' then
            col++
            pos++
         elseif c is '\n' then
            line++
            col = 0
            pos++
         elseif c is '\r' then
            pos++
            if pos < len and Source:sub(pos, pos + 1) is '\n' then
               pos++
            end
            line++
            col = 0
         else
            break
         end
      end
   end

   -- Check if character is identifier start
   function isIdentStart(C)
      return (C >= 'a' and C <= 'z') or (C >= 'A' and C <= 'Z') or C is '_'
   end

   -- Check if character is identifier continuation
   function isIdentChar(C)
      return isIdentStart(C) or (C >= '0' and C <= '9')
   end

   -- Check if character is digit
   function isDigit(C)
      return C >= '0' and C <= '9'
   end

   -- Main tokenization loop
   while pos < len do
      skipWhitespace()
      if pos >= len then break end

      c = Source:sub(pos, pos + 1)
      start_col = col
      start_pos = pos

      -- Line comment: --
      if c is '-' and pos + 1 < len and Source:sub(pos + 1, pos + 2) is '-' then
         comment_start = col

         -- Check for block comment --[[
         if pos + 3 < len and Source:sub(pos + 2, pos + 4) is '[[' then
            pos += 4
            col += 4
            -- Find closing ]]
            while pos < len do
               if Source:sub(pos, pos + 2) is ']]' then
                  pos += 2
                  col += 2
                  break
               elseif Source:sub(pos, pos + 1) is '\n' then
                  -- Only add token if there's content on this line
                  if col > comment_start then
                     addToken(line, comment_start, col - comment_start, 6, 0)  -- comment
                  end
                  line++
                  col = 0
                  pos++
                  comment_start = 0
               else
                  pos++
                  col++
               end
            end
            -- Add final line of block comment if there's content
            if col > comment_start then
               addToken(line, comment_start, col - comment_start, 6, 0)  -- comment
            end
         else
            -- Line comment - find end of line
            while pos < len and Source:sub(pos, pos + 1) != '\n' do
               pos++
               col++
            end
            addToken(line, comment_start, col - comment_start, 6, 0)  -- comment
         end

      -- String literals
      elseif c is '"' or c is "'" then
         quote = c
         str_start = col
         pos++
         col++
         while pos < len do
            sc = Source:sub(pos, pos + 1)
            if sc is quote then
               pos++
               col++
               break
            elseif sc is '\\' then
               pos += 2
               col += 2
            elseif sc is '\n' then
               break  -- Unterminated string
            else
               pos++
               col++
            end
         end
         addToken(line, str_start, col - str_start, 4, 0)  -- string

      -- Multiline string [[
      elseif c is '[' and pos + 1 < len and Source:sub(pos + 1, pos + 2) is '[' then
         str_start_line = line
         str_start_col = col
         pos += 2
         col += 2
         segment_start = col
         while pos < len do
            if Source:sub(pos, pos + 2) is ']]' then
               if col > segment_start or line is str_start_line then
                  addToken(line, (line is str_start_line) and str_start_col or 0,
                     (line is str_start_line) and (col - str_start_col + 2) or (col + 2), 4, 0)
               end
               pos += 2
               col += 2
               break
            elseif Source:sub(pos, pos + 1) is '\n' then
               if line is str_start_line then
                  addToken(line, str_start_col, col - str_start_col, 4, 0)
               else
                  addToken(line, 0, col, 4, 0)
               end
               line++
               col = 0
               pos++
               segment_start = 0
            else
               pos++
               col++
            end
         end

      -- Numbers
      elseif isDigit(c) or (c is '.' and pos + 1 < len and isDigit(Source:sub(pos + 1, pos + 2))) then
         num_start = col
         -- Hex number
         if c is '0' and pos + 1 < len and (Source:sub(pos + 1, pos + 2) is 'x' or Source:sub(pos + 1, pos + 2) is 'X') then
            pos += 2
            col += 2
            while pos < len do
               nc = Source:sub(pos, pos + 1)
               if isDigit(nc) or (nc >= 'a' and nc <= 'f') or (nc >= 'A' and nc <= 'F') then
                  pos++
                  col++
               else
                  break
               end
            end
         else
            -- Decimal number
            while pos < len and isDigit(Source:sub(pos, pos + 1)) do
               pos++
               col++
            end
            -- Decimal part
            if pos < len and Source:sub(pos, pos + 1) is '.' then
               pos++
               col++
               while pos < len and isDigit(Source:sub(pos, pos + 1)) do
                  pos++
                  col++
               end
            end
            -- Exponent
            if pos < len and (Source:sub(pos, pos + 1) is 'e' or Source:sub(pos, pos + 1) is 'E') then
               pos++
               col++
               if pos < len and (Source:sub(pos, pos + 1) is '+' or Source:sub(pos, pos + 1) is '-') then
                  pos++
                  col++
               end
               while pos < len and isDigit(Source:sub(pos, pos + 1)) do
                  pos++
                  col++
               end
            end
         end
         addToken(line, num_start, col - num_start, 5, 0)  -- number

      -- Identifiers and keywords
      elseif isIdentStart(c) then
         ident_start = col
         while pos < len and isIdentChar(Source:sub(pos, pos + 1)) do
            pos++
            col++
         end
         ident = Source:sub(start_pos, pos)
         ident_len = col - ident_start

         if FLUID_KEYWORDS[ident] then
            addToken(line, ident_start, ident_len, 0, 0)  -- keyword
         elseif FLUID_OPERATORS[ident] then
            addToken(line, ident_start, ident_len, 1, 0)  -- operator
         elseif FLUID_CONSTANTS[ident] then
            addToken(line, ident_start, ident_len, 12, 4)  -- macro + readonly
         elseif FLUID_BUILTINS[ident] then
            addToken(line, ident_start, ident_len, 3, 128)  -- function + defaultLibrary
         elseif FLUID_MODULES[ident] then
            addToken(line, ident_start, ident_len, 10, 0)  -- namespace
         elseif ident:match('^ERR_') then
            addToken(line, ident_start, ident_len, 12, 4)  -- macro + readonly (error constants)
         elseif ident:match('^gl[A-Z]') then
            addToken(line, ident_start, ident_len, 2, 8)  -- variable + static (global)
         elseif ident:match('^[A-Z]') and ident:match('^[A-Z_]+$') then
            addToken(line, ident_start, ident_len, 12, 4)  -- macro + readonly (CONSTANTS)
         else
            -- Check if it's a function call (followed by parenthesis)
            -- Save all position state since skipWhitespace may cross newlines
            save_pos = pos
            save_col = col
            save_line = line
            skipWhitespace()
            if pos < len and Source:sub(pos, pos + 1) is '(' then
               addToken(save_line, ident_start, ident_len, 3, 0)  -- function
            end
            -- Restore position (we don't consume the paren)
            pos = save_pos
            col = save_col
            line = save_line
         end

      -- Symbolic operators (multi-character first, then single-character)
      elseif c is '?' then
         op_start = col
         if pos + 2 < len and Source:sub(pos + 1, pos + 3) is '?=' then
            -- ??= if-empty assignment
            addToken(line, op_start, 3, 1, 0)
            pos += 3
            col += 3
         elseif pos + 1 < len and Source:sub(pos + 1, pos + 2) is '?' then
            -- ?? if-empty operator
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         elseif pos + 1 < len and Source:sub(pos + 1, pos + 2) is '=' then
            -- ?= if-nil assignment
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         elseif pos + 1 < len and Source:sub(pos + 1, pos + 2) is '.' then
            -- ?. safe navigation
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         elseif pos + 1 < len and Source:sub(pos + 1, pos + 2) is '[' then
            -- ?[ safe index
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- ? ternary condition
            addToken(line, op_start, 1, 1, 0)
            pos++
            col++
         end

      elseif c is '|' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '>' then
            -- |> pipe operator
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- | bitwise OR
            addToken(line, op_start, 1, 1, 0)
            pos++
            col++
         end

      elseif c is '=' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '>' then
            -- => arrow function
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- = assignment (skip, not highlighted as operator)
            pos++
            col++
         end

      elseif c is ':' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '>' then
            -- :> ternary else
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- : type annotation or method call (skip)
            pos++
            col++
         end

      elseif c is '.' then
         op_start = col
         if pos + 2 < len and Source:sub(pos + 1, pos + 3) is '.=' then
            -- ..= concatenation assignment
            addToken(line, op_start, 3, 1, 0)
            pos += 3
            col += 3
         elseif pos + 2 < len and Source:sub(pos + 1, pos + 3) is '..' then
            -- ... varargs or inclusive range
            addToken(line, op_start, 3, 1, 0)
            pos += 3
            col += 3
         elseif pos + 1 < len and Source:sub(pos + 1, pos + 2) is '.' then
            -- .. concatenation or exclusive range
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- . field access (skip)
            pos++
            col++
         end

      elseif c is '+' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '+' then
            -- ++ increment
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         elseif pos + 1 < len and Source:sub(pos + 1, pos + 2) is '=' then
            -- += compound assignment
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- + addition
            addToken(line, op_start, 1, 1, 0)
            pos++
            col++
         end

      elseif c is '-' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '=' then
            -- -= compound assignment
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- - subtraction/negation
            addToken(line, op_start, 1, 1, 0)
            pos++
            col++
         end

      elseif c is '*' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '=' then
            -- *= compound assignment
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- * multiplication
            addToken(line, op_start, 1, 1, 0)
            pos++
            col++
         end

      elseif c is '/' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '=' then
            -- /= compound assignment
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- / division
            addToken(line, op_start, 1, 1, 0)
            pos++
            col++
         end

      elseif c is '%' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '=' then
            -- %= compound assignment
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- % modulo
            addToken(line, op_start, 1, 1, 0)
            pos++
            col++
         end

      elseif c is '<' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '<' then
            -- << left shift
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         elseif pos + 1 < len and Source:sub(pos + 1, pos + 2) is '=' then
            -- <= less than or equal
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- < less than
            addToken(line, op_start, 1, 1, 0)
            pos++
            col++
         end

      elseif c is '>' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '>' then
            -- >> right shift
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         elseif pos + 1 < len and Source:sub(pos + 1, pos + 2) is '=' then
            -- >= greater than or equal
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- > greater than
            addToken(line, op_start, 1, 1, 0)
            pos++
            col++
         end

      elseif c is '!' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '=' then
            -- != not equal
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- ! (used in flags like '!READ')
            pos++
            col++
         end

      elseif c is '&' then
         -- & bitwise AND
         addToken(line, col, 1, 1, 0)
         pos++
         col++

      elseif c is '~' then
         -- ~ bitwise NOT
         addToken(line, col, 1, 1, 0)
         pos++
         col++

      elseif c is '^' then
         -- ^ exponentiation
         addToken(line, col, 1, 1, 0)
         pos++
         col++

      elseif c is '#' then
         -- # length operator
         addToken(line, col, 1, 1, 0)
         pos++
         col++

      else
         -- Skip other characters (punctuation, brackets, etc.)
         pos++
         col++
      end
   end

   return tokens
end

----------------------------------------------------------------------------------------------------------------------
-- LSP Symbol Kinds (subset used for Fluid)

SYMBOL_KIND = {
   FILE = 1,
   MODULE = 2,
   NAMESPACE = 3,
   PACKAGE = 4,
   CLASS = 5,
   METHOD = 6,
   PROPERTY = 7,
   FIELD = 8,
   CONSTRUCTOR = 9,
   ENUM = 10,
   INTERFACE = 11,
   FUNCTION = 12,
   VARIABLE = 13,
   CONSTANT = 14,
   STRING = 15,
   NUMBER = 16,
   BOOLEAN = 17,
   ARRAY = 18,
   OBJECT = 19,
   KEY = 20,
   NULL = 21,
   ENUM_MEMBER = 22,
   STRUCT = 23,
   EVENT = 24,
   OPERATOR = 25,
   TYPE_PARAMETER = 26
}

----------------------------------------------------------------------------------------------------------------------
-- Find the line number of the matching 'end' for a block starting at StartLine

function findMatchingEnd(Doc:table, StartLine:num):num
   depth = 1
   line_num = StartLine + 1
   total_lines = getTotalLines(Doc)

   while line_num < total_lines do
      line_text = getLine(Doc, line_num)

      -- Count block openers (simplified - doesn't handle strings/comments perfectly)
      for opener in line_text:gmatch('%f[%w]function%f[^%w]') do depth++ end
      for opener in line_text:gmatch('%f[%w]if%f[^%w]') do
         if line_text:match('%f[%w]if%f[^%w].*%f[%w]then%f[^%w]') then
            depth++
         end
      end
      for opener in line_text:gmatch('%f[%w]for%f[^%w]') do
         if line_text:match('%f[%w]for%f[^%w].*%f[%w]do%f[^%w]') then
            depth++
         end
      end
      for opener in line_text:gmatch('%f[%w]while%f[^%w]') do
         if line_text:match('%f[%w]while%f[^%w].*%f[%w]do%f[^%w]') then
            depth++
         end
      end
      for opener in line_text:gmatch('%f[%w]repeat%f[^%w]') do depth++ end
      for opener in line_text:gmatch('%f[%w]defer%f[^%w]') do depth++ end

      -- Count block closers
      for closer in line_text:gmatch('%f[%w]end%f[^%w]') do depth -= 1 end
      for closer in line_text:gmatch('%f[%w]until%f[^%w]') do depth -= 1 end

      if depth <= 0 then
         return line_num
      end

      line_num++
   end

   -- If no matching end found, return last line
   return total_lines - 1
end

----------------------------------------------------------------------------------------------------------------------
-- Extract document symbols (functions, globals) from Fluid source
-- Returns array of DocumentSymbol objects for the outline view

function extractDocumentSymbols(Doc:table):array
   symbols = array<table>
   total_lines = getTotalLines(Doc)
   in_block_comment = false

   for line_num = 0, total_lines - 1 do
      line_text = getLine(Doc, line_num)

      -- Track block comments --[[ ... ]]
      if in_block_comment then
         if line_text:find('%]%]') then
            in_block_comment = false
         end
         continue
      end

      -- Check for block comment start
      if line_text:find('%-%-%[%[') then
         in_block_comment = true
         continue
      end

      -- Skip line comments (lines starting with --)
      trimmed = line_text:match('^%s*(.*)')
      if trimmed:sub(0, 2) is '--' then
         continue
      end

      -- Check if 'function' appears before any line comment
      comment_pos = line_text:find('%-%-')
      func_pos = line_text:find('function%s+[%w_]')

      -- Skip if function keyword is inside a line comment
      if func_pos and comment_pos and comment_pos < func_pos then
         continue
      end

      if func_pos then
         -- Extract everything after 'function '
         after_func = line_text:sub(func_pos)
         name = after_func:match('^function%s+([%w_:%.]+)')

         if name then
            -- Determine scope by looking before 'function'
            before_func = line_text:sub(0, func_pos)
            scope = nil
            if before_func:match('local%s*$') then
               scope = 'local'
            elseif before_func:match('global%s*$') then
               scope = 'global'
            end

            -- Find the column where the name starts (0-based)
            name_start = line_text:find(name, func_pos, true)
            name_start = name_start and (name_start - 1) or 0

            -- Determine symbol kind based on name pattern
            kind = SYMBOL_KIND.FUNCTION
            if name:find(':') then
               kind = SYMBOL_KIND.METHOD  -- Class:method style
            end

            -- Find the end of this function (matching 'end')
            end_line = findMatchingEnd(Doc, line_num)

            symbol = {
               name = name,
               kind = kind,
               range = {
                  start = { line = line_num, character = 0 },
                  ['end'] = { line = end_line, character = #getLine(Doc, end_line) }
               },
               selectionRange = {
                  start = { line = line_num, character = name_start },
                  ['end'] = { line = line_num, character = name_start + #name }
               }
            }

            if scope then
               symbol.detail = scope
            end

            symbols:push(symbol)
         end
      end
   end

   return symbols
end

----------------------------------------------------------------------------------------------------------------------
-- LSP Folding Range Kinds

FOLDING_KIND = {
   COMMENT = 'comment',
   IMPORTS = 'imports',
   REGION = 'region'
}

----------------------------------------------------------------------------------------------------------------------
-- Extract folding ranges from Fluid source
-- Returns array of FoldingRange objects for code folding

function extractFoldingRanges(Doc:table):array
   ranges = array<table>
   total_lines = getTotalLines(Doc)
   block_stack = array<table>  -- Stack of { line, kind } for nested blocks
   in_block_comment = false
   block_comment_start = 0

   for line_num = 0, total_lines - 1 do
      line_text = getLine(Doc, line_num)

      -- Handle block comments --[[ ... ]]
      if in_block_comment then
         if line_text:find('%]%]') then
            -- End of block comment
            if line_num > block_comment_start then
               ranges:push({
                  startLine = block_comment_start,
                  endLine = line_num,
                  kind = FOLDING_KIND.COMMENT
               })
            end
            in_block_comment = false
         end
         continue
      end

      -- Check for block comment start
      block_comment_pos = line_text:find('%-%-%[%[')
      if block_comment_pos then
         -- Check it's not inside a string (simplified check)
         before = line_text:sub(0, block_comment_pos)
         if not before:find('["\']') then
            in_block_comment = true
            block_comment_start = line_num
            continue
         end
      end

      -- Check for block openers: function, if...then, for...do, while...do, repeat, defer
      -- We need to be careful not to match keywords in comments or strings

      -- Skip if line is a comment
      trimmed = line_text:match('^%s*(.*)')
      if trimmed:sub(0, 2) is '--' then
         continue
      end

      -- Find comment position to avoid matching keywords in comments
      comment_pos = line_text:find('%-%-')

      -- Check for block openers (only if not in a comment)
      function checkKeyword(Pattern)
         pos = line_text:find(Pattern)
         if pos and (not comment_pos or pos < comment_pos) then
            return pos
         end
         return nil
      end

      -- function ... (opens a block)
      if checkKeyword('%f[%w]function%s+[%w_]') or checkKeyword('%f[%w]function%s*%(') then
         block_stack:push({ line = line_num, kind = 'function' })
      end

      -- if ... then (opens a block)
      if checkKeyword('%f[%w]if%f[^%w]') and checkKeyword('%f[%w]then%f[^%w]') then
         block_stack:push({ line = line_num, kind = 'if' })
      end

      -- for ... do (opens a block)
      if checkKeyword('%f[%w]for%f[^%w]') and checkKeyword('%f[%w]do%f[^%w]') then
         block_stack:push({ line = line_num, kind = 'for' })
      end

      -- while ... do (opens a block)
      if checkKeyword('%f[%w]while%f[^%w]') and checkKeyword('%f[%w]do%f[^%w]') then
         block_stack:push({ line = line_num, kind = 'while' })
      end

      -- repeat (opens a block, closed by until)
      if checkKeyword('%f[%w]repeat%f[^%w]') then
         block_stack:push({ line = line_num, kind = 'repeat' })
      end

      -- defer (opens a block)
      if checkKeyword('%f[%w]defer%f[^%w]') then
         block_stack:push({ line = line_num, kind = 'defer' })
      end

      -- Check for block closers
      -- 'end' closes function, if, for, while, defer
      if checkKeyword('%f[%w]end%f[^%w]') then
         if #block_stack > 0 then
            block_start = block_stack:pop()
            if block_start and line_num > block_start.line then
               ranges:push({
                  startLine = block_start.line,
                  endLine = line_num
               })
            end
         end
      end

      -- 'until' closes repeat
      if checkKeyword('%f[%w]until%f[^%w]') then
         if #block_stack > 0 then
            block_start = block_stack:pop()
            if block_start and block_start.kind is 'repeat' and line_num > block_start.line then
               ranges:push({
                  startLine = block_start.line,
                  endLine = line_num
               })
            end
         end
      end
   end

   return ranges
end

----------------------------------------------------------------------------------------------------------------------
-- Encode tokens into LSP semantic tokens format (delta-encoded integers)

function encodeSemanticTokens(Tokens:array):array
   data = array<int>
   prev_line = 0
   prev_char = 0

   for tok in values(Tokens) do
      delta_line = tok.line - prev_line
      delta_char = (delta_line is 0) and (tok.char - prev_char) or tok.char

      data:push(delta_line)
      data:push(delta_char)
      data:push(tok.length)
      data:push(tok.type)
      data:push(tok.modifiers)

      prev_line = tok.line
      prev_char = tok.char
   end

   return data
end

----------------------------------------------------------------------------------------------------------------------
-- Compute semantic token edits between old and new data arrays
-- Returns array of SemanticTokensEdit: { start, deleteCount, data? }

function computeTokenEdits(OldData:array, NewData:array):array
   old_len = #OldData
   new_len = #NewData

   -- Find common prefix (in groups of 5 integers = 1 token)
   prefix_tokens = 0
   max_prefix = math.min(old_len, new_len) / 5
   while prefix_tokens < max_prefix do
      idx = prefix_tokens * 5
      match = true
      for i = 0, 4 do
         if OldData[idx + i] != NewData[idx + i] then
            match = false
            break
         end
      end
      if not match then break end
      prefix_tokens++
   end

   -- Find common suffix (in groups of 5 integers = 1 token)
   suffix_tokens = 0
   old_suffix_start = old_len
   new_suffix_start = new_len
   max_suffix = math.min((old_len / 5) - prefix_tokens, (new_len / 5) - prefix_tokens)

   while suffix_tokens < max_suffix do
      old_idx = old_len - (suffix_tokens + 1) * 5
      new_idx = new_len - (suffix_tokens + 1) * 5
      match = true
      for i = 0, 4 do
         if OldData[old_idx + i] != NewData[new_idx + i] then
            match = false
            break
         end
      end
      if not match then break end
      suffix_tokens++
   end

   -- Calculate the range that differs
   prefix_ints = prefix_tokens * 5
   suffix_ints = suffix_tokens * 5

   delete_start = prefix_ints
   delete_count = old_len - prefix_ints - suffix_ints
   insert_count = new_len - prefix_ints - suffix_ints

   -- If nothing changed, return empty edits
   if delete_count is 0 and insert_count is 0 then
      return array<table>
   end

   -- Build the edit
   edit = {
      start = delete_start,
      deleteCount = delete_count
   }

   -- Include new data if we're inserting anything
   if insert_count > 0 then
      edit.data = array<int>
      for i = prefix_ints, prefix_ints + insert_count - 1 do
         edit.data:push(NewData[i])
      end
   end

   return array<table> { edit }
end

----------------------------------------------------------------------------------------------------------------------
-- Core LSP Handlers

function registerCoreHandlers(Self)
   -- initialize: Client initiates handshake
   Self._handlers['initialize'] = function(Msg, State)
      State.initialized = true
      logMessage(Self, 'LSP initialize request received')

      return {
         jsonrpc = '2.0',
         id = Msg.id,
         result = {
            capabilities = {
               -- Incremental sync: client sends only changed portions
               textDocumentSync = {
                  openClose = true,
                  change = 2  -- Incremental sync
               },
               -- Semantic tokens for syntax highlighting
               semanticTokensProvider = {
                  legend = {
                     tokenTypes = TOKEN_TYPES,
                     tokenModifiers = TOKEN_MODIFIERS
                  },
                  full = {
                     delta = true  -- Support delta updates for efficiency
                  },
                  range = false
               },
               -- Document symbols for outline view
               documentSymbolProvider = true,
               -- Folding ranges for code folding
               foldingRangeProvider = true,
               -- Hover information
               hoverProvider = true
            },
            serverInfo = {
               name = 'Fluid LSP Server',
               version = '0.1.0'
            }
         }
      }
   end

   -- initialized: Client confirms handshake complete (notification, no response)
   Self._handlers['initialized'] = function(Msg, State)
      logMessage(Self, 'LSP initialized notification received - handshake complete')
      return nil
   end

   -- shutdown: Client requests shutdown preparation
   Self._handlers['shutdown'] = function(Msg, State)
      State.shutdown_requested = true
      logMessage(Self, 'LSP shutdown request received')

      return {
         jsonrpc = '2.0',
         id = Msg.id,
         result = json.null
      }
   end

   -- exit: Client requests termination (notification)
   Self._handlers['exit'] = function(Msg, State)
      if State.shutdown_requested then
         logMessage(Self, 'LSP exit notification - clean shutdown')
      else
         logMessage(Self, 'LSP exit notification - unexpected (no prior shutdown)')
      end
      State.should_disconnect = true
      return nil
   end

   -- $/cancelRequest: Client wants to cancel a pending request (notification)
   -- Since we process requests synchronously, we just acknowledge and ignore
   Self._handlers['$/cancelRequest'] = function(Msg, State)
      logVerbose(Self, 'Cancel request received for id: ' .. tostring(Msg.params.id))
      return nil  -- Notification, no response
   end

   --------------------------------------------------------------------------
   -- Document Synchronization

   -- textDocument/didOpen: Client opened a document
   Self._handlers['textDocument/didOpen'] = function(Msg, State)
      doc = Msg.params.textDocument
      glDocuments[doc.uri] = {
         uri = doc.uri,
         languageId = doc.languageId,
         version = doc.version,
         content = doc.text,
         lineIndex = nil  -- Lazily computed line index
      }
      logMessage(Self, 'Document opened: ' .. doc.uri)

      -- Compute and publish diagnostics
      params = computeDiagnostics(glDocuments[doc.uri])
      sendNotification(Self, State.clientSocket, 'textDocument/publishDiagnostics', params)

      return nil  -- Notification, no response
   end

   -- textDocument/didChange: Document content changed
   Self._handlers['textDocument/didChange'] = function(Msg, State)
      uri = Msg.params.textDocument.uri
      version = Msg.params.textDocument.version

      if glDocuments[uri] then
         edit_line = nil  -- Track earliest edited line for incremental index update
         for change in values(Msg.params.contentChanges) do
            if change.range then
               -- Track the earliest line affected by edits
               if not edit_line or change.range.start.line < edit_line then
                  edit_line = change.range.start.line
               end
               -- Incremental sync: apply text edit at range
               glDocuments[uri].content = applyTextEdit(
                  glDocuments[uri].content,
                  change.range,
                  change.text
               )
            else
               -- Full sync fallback: replace entire content
               glDocuments[uri].content = change.text
               edit_line = 0  -- Force full rebuild
            end
         end
         glDocuments[uri].version = version

         -- Incrementally rebuild line index from the edited line
         markLineIndex(glDocuments[uri], edit_line)

         logVerbose(Self, 'Document updated: ' .. uri .. ' (version ' .. version .. ')')

         -- Compute and publish diagnostics
         params = computeDiagnostics(glDocuments[uri])
         sendNotification(Self, State.clientSocket, 'textDocument/publishDiagnostics', params)
      end
      return nil  -- Notification, no response
   end

   -- textDocument/didClose: Client closed a document
   Self._handlers['textDocument/didClose'] = function(Msg, State)
      uri = Msg.params.textDocument.uri
      glDocuments[uri] = nil
      glTokenCache[uri] = nil  -- Clear token cache to free memory
      logMessage(Self, 'Document closed: ' .. uri)

      -- Clear diagnostics for closed document
      sendNotification(Self, State.clientSocket, 'textDocument/publishDiagnostics', {
         uri = uri,
         diagnostics = array<table>
      })

      return nil  -- Notification, no response
   end

   --------------------------------------------------------------------------
   -- Semantic Tokens

   -- textDocument/semanticTokens/full: Return all semantic tokens for a document

   Self._handlers['textDocument/semanticTokens/full'] = function(Msg, State)
      uri = Msg.params.textDocument.uri
      doc = glDocuments[uri]

      if not doc then
         logMessage(Self, 'Semantic tokens requested for unknown document: ' .. uri)
         return {
            jsonrpc = '2.0',
            id = Msg.id,
            result = { data = array<int> }
         }
      end

      logVerbose(Self, 'Computing semantic tokens for: ' .. uri)

      tokens = tokenizeFluid(doc.content)
      encoded = encodeSemanticTokens(tokens)

      -- Generate resultId and cache for delta requests
      result_id = tostring(glNextResultId)
      glNextResultId++

      glTokenCache[uri] = {
         resultId = result_id,
         data = encoded
      }

      logVerbose(Self, 'Returning ' .. #tokens .. ' tokens (' .. #encoded .. ' integers), resultId=' .. result_id)

      return {
         jsonrpc = '2.0',
         id = Msg.id,
         result = {
            resultId = result_id,
            data = encoded
         }
      }
   end

   -- textDocument/semanticTokens/full/delta: Return only changed semantic tokens
   Self._handlers['textDocument/semanticTokens/full/delta'] = function(Msg, State)
      uri = Msg.params.textDocument.uri
      previous_result_id = Msg.params.previousResultId
      doc = glDocuments[uri]

      if not doc then
         logMessage(Self, 'Semantic tokens delta requested for unknown document: ' .. uri)
         return {
            jsonrpc = '2.0',
            id = Msg.id,
            result = { data = array<int> }
         }
      end

      -- Check if we have the previous result cached
      cached = glTokenCache[uri]
      if not cached or cached.resultId != previous_result_id then
         -- Can't compute delta, return full tokens
         logWarning(Self, 'Cannot compute delta (no cache or resultId mismatch), returning full tokens')

         tokens = tokenizeFluid(doc.content)
         encoded = encodeSemanticTokens(tokens)

         result_id = tostring(glNextResultId)
         glNextResultId++

         glTokenCache[uri] = {
            resultId = result_id,
            data = encoded
         }

         return {
            jsonrpc = '2.0',
            id = Msg.id,
            result = {
               resultId = result_id,
               data = encoded
            }
         }
      end

      logVerbose(Self, 'Computing semantic tokens delta for: ' .. uri)

      -- Compute new tokens
      tokens = tokenizeFluid(doc.content)
      new_encoded = encodeSemanticTokens(tokens)

      -- Compute delta between old and new
      edits = computeTokenEdits(cached.data, new_encoded)

      -- Generate new resultId and update cache
      result_id = tostring(glNextResultId)
      glNextResultId++

      glTokenCache[uri] = {
         resultId = result_id,
         data = new_encoded
      }

      -- Calculate edit size for logging
      edit_size = 0
      for edit in values(edits) do
         edit_size += (edit.data and #edit.data or 0)
      end

      logVerbose(Self, 'Returning ' .. #edits .. ' edits (' .. edit_size .. ' integers vs ' .. #new_encoded .. ' full), resultId=' .. result_id)

      return {
         jsonrpc = '2.0',
         id = Msg.id,
         result = {
            resultId = result_id,
            edits = edits
         }
      }
   end

   --------------------------------------------------------------------------
   -- Document Symbols (Outline View)

   -- textDocument/documentSymbol: Return symbols for outline view
   Self._handlers['textDocument/documentSymbol'] = function(Msg, State)
      uri = Msg.params.textDocument.uri
      doc = glDocuments[uri]

      if not doc then
         logMessage(Self, 'Document symbols requested for unknown document: ' .. uri)
         return {
            jsonrpc = '2.0',
            id = Msg.id,
            result = array<table>
         }
      end

      logVerbose(Self, 'Computing document symbols for: ' .. uri)

      symbols = extractDocumentSymbols(doc)

      logVerbose(Self, 'Returning ' .. #symbols .. ' symbols')

      return {
         jsonrpc = '2.0',
         id = Msg.id,
         result = symbols
      }
   end

   --------------------------------------------------------------------------
   -- Folding Ranges (Code Folding)

   -- textDocument/foldingRange: Return folding ranges for code folding
   Self._handlers['textDocument/foldingRange'] = function(Msg, State)
      uri = Msg.params.textDocument.uri
      doc = glDocuments[uri]

      if not doc then
         logMessage(Self, 'Folding ranges requested for unknown document: ' .. uri)
         return {
            jsonrpc = '2.0',
            id = Msg.id,
            result = array<table>
         }
      end

      logVerbose(Self, 'Computing folding ranges for: ' .. uri)

      ranges = extractFoldingRanges(doc)

      logVerbose(Self, 'Returning ' .. #ranges .. ' folding ranges')

      return {
         jsonrpc = '2.0',
         id = Msg.id,
         result = ranges
      }
   end

   --------------------------------------------------------------------------
   -- Hover Information

   -- textDocument/hover: Return documentation for symbol at cursor
   Self._handlers['textDocument/hover'] = function(Msg, State)
      uri = Msg.params.textDocument.uri
      position = Msg.params.position
      doc = glDocuments[uri]

      if not doc then
         logMessage(Self, 'Hover requested for unknown document: ' .. uri)
         return {
            jsonrpc = '2.0',
            id = Msg.id,
            result = json.null
         }
      end

      -- Get the token at the hover position
      tokenInfo = getTokenAtPosition(doc, position.line, position.character)

      if not tokenInfo then
         return {
            jsonrpc = '2.0',
            id = Msg.id,
            result = json.null
         }
      end

      logVerbose(Self, 'Hover: token="' .. tokenInfo.text .. '" context=' .. tokenInfo.context ..
         (tokenInfo.object and (' object=' .. tokenInfo.object) or ''))

      -- Attempt to resolve documentation
      hoverContent = resolveHoverContent(tokenInfo, doc)

      if not hoverContent then
         return {
            jsonrpc = '2.0',
            id = Msg.id,
            result = json.null
         }
      end

      return {
         jsonrpc = '2.0',
         id = Msg.id,
         result = {
            contents = {
               kind = 'markdown',
               value = hoverContent
            },
            range = {
               start = { line = position.line, character = tokenInfo.startCol },
               ['end'] = { line = position.line, character = tokenInfo.endCol }
            }
         }
      }
   end
end

----------------------------------------------------------------------------------------------------------------------
-- Documentation Cache Builder
--
-- Builds an index of Parasol API documentation from XML files.
-- Stores top-level info (names, comments, prototypes) plus byte offsets for on-demand detail retrieval.
--
-- Compact string format uses \0 as field separator:
--   Fields:  'A:access\0L:start,end\0T:type\0C:comment'
--   Methods: 'L:start,end\0P:prototype\0C:comment'
--   Actions: 'L:start,end\0P:prototype\0C:comment'
--   Functions: 'L:start,end\0P:prototype\0C:comment'

-- Encode a field entry to compact string format
function encodeField(Access, Type, ByteStart, ByteEnd, Comment)
   return 'A:' .. (Access or 'R') .. '\0L:' .. ByteStart .. ',' .. ByteEnd ..
          '\0T:' .. (Type or '') .. '\0C:' .. (Comment or '')
end

-- Encode a method/action/function entry to compact string format
function encodeMethod(Prototype, ByteStart, ByteEnd, Comment)
   return 'L:' .. ByteStart .. ',' .. ByteEnd ..
          '\0P:' .. (Prototype or '') .. '\0C:' .. (Comment or '')
end

-- Decode a field from compact string format
function decodeField(Str:any):table
   if type(Str) != 'string' then return Str end  -- Already decoded or nil

   result = {}
   for field in values(Str:split('\0')) do
      key = field:sub(0, 1)
      value = field:sub(2)
      if key is 'A' then
         result.access = value
      elseif key is 'L' then
         start_pos, end_pos = value:match('(%d+),(%d+)')
         result.byteStart = tonumber(start_pos)
         result.byteEnd = tonumber(end_pos)
      elseif key is 'T' then
         result.type = value
      elseif key is 'C' then
         result.comment = value
      else
         print('Unrecognised key: ' .. tostring(key))
      end
   end
   return result
end

-- Decode a method/action/function from compact string format

function decodeMethod(Str:any):table
   if type(Str) is 'table' then return Str end  -- Already decoded or nil

   result = {}
   for field in values(Str:split('\0')) do
      key = field:sub(0, 1)
      value = field:sub(2)
      if key is 'L' then
         start_pos, end_pos = value:match('(%d+),(%d+)')
         result.byteStart = tonumber(start_pos)
         result.byteEnd = tonumber(end_pos)
      elseif key is 'P' then
         result.prototype = value
      elseif key is 'C' then
         result.comment = value
      else
         print('Unrecognised key: ' .. tostring(key))
      end
   end

   return result
end

function parseAccessString(ReadAttr:str, WriteAttr:str):str
   -- Convert access attributes to simplified form: R, W, R/W, R/I, R/S, etc.
   r = ReadAttr and (ReadAttr is 'R' or ReadAttr is 'G') and 'R' or nil
   w = nil
   if WriteAttr then
      if WriteAttr is 'W' then w = 'W'
      elseif WriteAttr is 'S' then w = 'S'
      elseif WriteAttr is 'I' then w = 'I'
      end
   end

   if r and w then return r .. '/' .. w
   elseif r then return r
   elseif w then return w
   else return 'R' end
end

function extractXMLElement(Content:str, TagName:str, StartPos):table
   -- Find an XML element and return its content plus byte positions
   openTag = '<' .. TagName .. '>'
   closeTag = '</' .. TagName .. '>'

   tagStart = Content:find(openTag, StartPos)
   tagStart ?? return

   tagEnd = Content:find(closeTag, tagStart)
   tagEnd ?? return

   content = Content:sub(tagStart + #openTag, tagEnd - 1)
   content = content?:unescapeXML()

   return {
      byteStart = tagStart,
      byteEnd = tagEnd + #closeTag - 1,
      content = content
   }
end

function extractChildText(Content:str, TagName:str):str
   -- Extract text content of a child element
   pattern = '<' .. TagName .. '>([^<]*)</' .. TagName .. '>'
   content = Content:match(pattern)
   content?:unescapeXML()
   return content
end

function extractChildAttr(Content:str, TagName:str, AttrName:str):str
   -- Extract attribute value from a child element
   pattern = '<' .. TagName .. '[^>]*' .. AttrName .. '="([^"]*)"'
   content = Content:match(pattern)
   content?:unescapeXML()
   return content
end

function processModuleXML(FilePath:str, DocPath:str):<str,table>
   -- Process a module XML file and extract function information
   content = file.readAll(FilePath)
   content ?? return

   relativePath = FilePath:gsub(DocPath, '')

   -- Extract module info
   infoMatch = extractXMLElement(content, 'info', 0)
   infoMatch ?? return

   modName = extractChildText(infoMatch.content, 'name')
   modName ?? return

   modEntry = {
      file = relativePath,
      comment = extractChildText(infoMatch.content, 'comment') or '',
      functions = {}
   }

   -- Extract functions (using compact string format)
   pos = 0
   while true do
      funcMatch = extractXMLElement(content, 'function', pos)
      funcMatch ?? break

      funcName = extractChildText(funcMatch.content, 'name')
      if funcName then
         modEntry.functions[funcName] = encodeMethod(
            extractChildText(funcMatch.content, 'prototype') or '',
            funcMatch.byteStart,
            funcMatch.byteEnd,
            extractChildText(funcMatch.content, 'comment') or ''
         )
      end

      pos = funcMatch.byteEnd
   end

   return modName, modEntry
end

----------------------------------------------------------------------------------------------------------------------
-- Process a class XML file and extract method/action/field information

function processClassXML(FilePath, DocPath)
   content = file.readAll(FilePath)
   content ?? return

   relativePath = FilePath:gsub(DocPath, '')

   -- Extract class info
   infoMatch = extractXMLElement(content, 'info', 0)
   infoMatch ?? return

   className = extractChildText(infoMatch.content, 'name')
   className ?? return

   classEntry = {
      file = relativePath,
      module = extractChildText(infoMatch.content, 'module') or '',
      comment = extractChildText(infoMatch.content, 'comment') or '',
      methods = {},
      actions = {},
      fields = {}
   }

   -- Extract methods (using compact string format)
   pos = 0
   while true do
      methodMatch = extractXMLElement(content, 'method', pos)
      methodMatch ?? break

      methodName = extractChildText(methodMatch.content, 'name')
      if methodName then
         classEntry.methods[methodName] = encodeMethod(
            extractChildText(methodMatch.content, 'prototype') or '',
            methodMatch.byteStart,
            methodMatch.byteEnd,
            extractChildText(methodMatch.content, 'comment') or ''
         )
      end

      pos = methodMatch.byteEnd
   end

   -- Extract actions (using compact string format)
   pos = 0
   while true do
      actionMatch = extractXMLElement(content, 'action', pos)
      actionMatch ?? break

      actionName = extractChildText(actionMatch.content, 'name')
      if actionName then
         classEntry.actions[actionName] = encodeMethod(
            extractChildText(actionMatch.content, 'prototype') or '',
            actionMatch.byteStart,
            actionMatch.byteEnd,
            extractChildText(actionMatch.content, 'comment') or ''
         )
      end

      pos = actionMatch.byteEnd
   end

   -- Extract fields (using compact string format)
   pos = 0
   while true do
      fieldMatch = extractXMLElement(content, 'field', pos)
      fieldMatch ?? break

      fieldName = extractChildText(fieldMatch.content, 'name')
      if fieldName then
         readAttr = extractChildAttr(fieldMatch.content, 'access', 'read')
         writeAttr = extractChildAttr(fieldMatch.content, 'access', 'write')

         classEntry.fields[fieldName] = encodeField(
            parseAccessString(readAttr, writeAttr),
            extractChildText(fieldMatch.content, 'type') or '',
            fieldMatch.byteStart,
            fieldMatch.byteEnd,
            extractChildText(fieldMatch.content, 'comment') or ''
         )
      end

      pos = fieldMatch.byteEnd
   end

   return className, classEntry
end

----------------------------------------------------------------------------------------------------------------------

function buildDocCache(DocPath)
   -- Build the documentation cache from XML files

   cache = {
      version = 1,
      built = mSys.PreciseTime() / 1000000,
      sdkPath = DocPath,
      modules = {},
      classes = {}
   }

   modulesPath = DocPath .. 'modules/'
   classesPath = DocPath .. 'modules/classes/'

   -- Process module XML files

   print('Scanning modules for documentation cache; ', modulesPath)

   err = file.search(modulesPath, {
      nameFilter = '%.xml$',
      nameWild = true,
      maxDepth = 0,
      matchFeedback = function(Path, FileName, File)
         -- Skip if it's a directory entry for 'classes'
         if FileName is 'classes' then return end

         fullPath = Path .. FileName
         modName, modEntry = processModuleXML(fullPath, DocPath)
         if modName and modEntry then
            cache.modules[modName] = modEntry
            msg('Found module ' .. modName .. ' @ ' .. fullPath)
         end
      end
   })

   collectgarbage()

   -- Process class XML files

   print('Scanning classes for documentation cache; ', classesPath)

   err = file.search(classesPath, {
      nameFilter = '%.xml$',
      nameWild = true,
      maxDepth = 1,
      matchFeedback = function(Path, FileName, File)
         fullPath = Path .. FileName
         className, classEntry = processClassXML(fullPath, DocPath)
         if className and classEntry then
            cache.classes[className] = classEntry
            msg('Found class ' .. className .. ' @ ' .. fullPath)
         end
      end
   })

   msg('Scan completed')

   collectgarbage()
   return cache
end

----------------------------------------------------------------------------------------------------------------------
-- Serialize a Lua table to a string representation

function serializeTable(Tbl:any, Indent):str
   Indent = Indent or ''
   nextIndent = Indent .. '   '

   if type(Tbl) != 'table' then
      if type(Tbl) is 'string' then
         -- Escape special characters
         escaped = Tbl:gsub('\\', '\\\\'):gsub('\n', '\\n'):gsub('\r', '\\r'):gsub("'", "\\'")
         return "'" .. escaped .. "'"
      elseif type(Tbl) is 'number' then
         return tostring(Tbl)
      elseif type(Tbl) is 'boolean' then
         return Tbl and 'true' or 'false'
      else
         return 'nil'
      end
   end

   parts = {}
   for k, v in pairs(Tbl) do
      keyStr = type(k) is 'string' and "['" .. k .. "']" or '[' .. tostring(k) .. ']'
      valStr = serializeTable(v, nextIndent)
      table.insert(parts, nextIndent .. keyStr .. ' = ' .. valStr)
   end

   if #parts is 0 then
      return '{}'
   end

   return '{\n' .. table.concat(parts, ',\n') .. '\n' .. Indent .. '}'
end

----------------------------------------------------------------------------------------------------------------------

function saveDocCache(CachePath, Cache)
   -- Save the cache as a Fluid script
   content = '-- Fluid LSP Documentation Cache\n'
   content ..= '-- Auto-generated, do not edit manually\n'
   content ..= '-- Built: ' .. timestamp() .. '\n\n'
   content ..= 'return ' .. serializeTable(Cache) .. '\n'

   file.writeAll(CachePath, content)
end

----------------------------------------------------------------------------------------------------------------------

function loadDocCache(DocPath)
   -- Attempt to load the cache, returns nil if invalid
   msg('Loading document cache from ' .. CACHE_PATH)
   ex, cache = catch(function()
      return loadFile(CACHE_PATH)
   end)

   if ex or not cache then msg('Failed to run cache file.  Error: ' .. tostring(ex.message)); return nil end
   if cache.version != 1 then msg('Unsupported version'); return nil end
   if cache.sdkPath != DocPath then msg('Path mismatch: ' .. cache.sdkPath .. ' != ' .. DocPath); return nil end

   return cache
end

----------------------------------------------------------------------------------------------------------------------
-- Hover Support - Token Extraction

global function getTokenAtPosition(Doc:table, Line:num, Character:num):table
   -- Extract the token/symbol at a given position in the document
   -- Returns: { text, object, startCol, endCol, context }
   -- context: 'identifier', 'method_call', 'field_access', 'module_call'

   lineText = getLine(Doc, Line)
   if not lineText or Character >= #lineText then return nil end

   -- Helper to check if character is identifier-like
   function isIdent(C)
      return (C >= 'a' and C <= 'z') or (C >= 'A' and C <= 'Z') or (C >= '0' and C <= '9') or C is '_'
   end

   -- Find token boundaries
   startCol = Character
   endCol = Character

   -- Scan backwards to find token start
   while startCol > 0 do
      c = lineText:sub(startCol - 1, startCol)
      if not isIdent(c) then break end
      startCol -= 1
   end

   -- Scan forward to find token end
   while endCol < #lineText do
      c = lineText:sub(endCol, endCol + 1)
      if not isIdent(c) then break end
      endCol++
   end

   if startCol is endCol then return nil end

   token = lineText:sub(startCol, endCol)
   context = 'identifier'
   precedingIdent = nil

   -- Check for preceding dot (field access or method call)
   if startCol > 0 then
      beforeStart = startCol - 1

      -- Skip whitespace
      while beforeStart > 0 and (lineText:sub(beforeStart, beforeStart + 1) is ' ' or lineText:sub(beforeStart, beforeStart + 1) is '\t') do
         beforeStart -= 1
      end

      if lineText:sub(beforeStart, beforeStart + 1) is '.' then
         -- Find the preceding identifier (the object/module name)
         objEnd = beforeStart
         objStart = beforeStart - 1

         while objStart > 0 and isIdent(lineText:sub(objStart - 1, objStart)) do
            objStart -= 1
         end

         if objStart < objEnd then
            precedingIdent = lineText:sub(objStart, objEnd)

            -- Check if followed by parenthesis (method call)
            afterEnd = endCol
            while afterEnd < #lineText and (lineText:sub(afterEnd, afterEnd + 1) is ' ' or lineText:sub(afterEnd, afterEnd + 1) is '\t') do
               afterEnd++
            end

            if lineText:sub(afterEnd, afterEnd + 1) is '(' then
               context = 'method_call'
            else
               context = 'field_access'
            end
         end
      end
   end

   return {
      text = token,
      object = precedingIdent,
      startCol = startCol,
      endCol = endCol,
      context = context
   }
end

----------------------------------------------------------------------------------------------------------------------
-- Hover Support - Type Inference

function buildTypeMap(Doc)
   -- Build a mapping of variable names to class types based on obj.new() calls
   typeMap = {}

   -- Match patterns like: varname = obj.new('classname' or varname = obj.new("classname"
   for varname, classname in Doc.content:gmatch("([%w_]+)%s*=%s*obj%.new%s*%(%s*['\"]([%w_]+)['\"]") do
      -- Capitalize first letter for class name lookup (e.g., 'netsocket' -> 'NetSocket')
      -- Most class names in the XML are in TitleCase
      normalizedClass = classname:sub(1,1):upper() .. classname:sub(2)
      typeMap[varname] = normalizedClass
   end

   return typeMap
end

----------------------------------------------------------------------------------------------------------------------
-- Hover Support - Content Resolution and Formatting

function formatClassHover(ClassName, ClassDoc)
   md = '**class ' .. ClassName .. '**\n\n'
   md ..= ClassDoc.comment
   if ClassDoc.module and #ClassDoc.module > 0 then
      md ..= '\n\n_Module: ' .. ClassDoc.module .. '_'
   end
   return md
end

function formatMethodHover(ClassName, MethodName, MethodDoc)
   doc = decodeMethod(MethodDoc)  -- Decode compact string if needed
   md = '**' .. ClassName .. '.' .. MethodName .. '**\n\n'
   if doc.prototype?? then
      md ..= '```c\n' .. doc.prototype .. '\n```\n\n'
   end
   md ..= doc.comment or ''
   return md
end

function formatActionHover(ClassName, ActionName, ActionDoc)
   doc = decodeMethod(ActionDoc)  -- Decode compact string if needed
   md = '**' .. ClassName .. '.ac' .. ActionName .. '** _(Action)_\n\n'
   if doc.prototype?? then
      md ..= '```c\n' .. doc.prototype .. '\n```\n\n'
   end
   md ..= doc.comment or ''
   return md
end

function formatFieldHover(ClassName, FieldName, FieldDoc)
   doc = decodeField(FieldDoc)  -- Decode compact string if needed
   md = '**' .. ClassName .. '.' .. FieldName .. '**\n\n'
   md ..= 'Type: `' .. (doc.type or 'unknown') .. '`'
   if doc.access then
      md ..= ' | Access: ' .. doc.access
   end
   md ..= '\n\n' .. (doc.comment or '')
   return md
end

function formatModuleFunctionHover(ModuleName, FuncName, FuncDoc)
   doc = decodeMethod(FuncDoc)  -- Decode compact string if needed
   md = '**' .. ModuleName .. '.' .. FuncName .. '**\n\n'
   if doc.prototype?? then
      md ..= '```c\n' .. doc.prototype .. '\n```\n\n'
   end
   md ..= doc.comment or ''
   md ..= '\n\n[Documentation](https://parasol.ws/modules/' .. ModuleName:lower() .. '.html?page=' .. FuncName .. ')'
   return md
end

function formatBuiltinHover(FuncName, BuiltinDoc)
   md = '**' .. FuncName .. '** _(Built-in)_\n\n'
   if BuiltinDoc.prototype?? then
      md ..= '```lua\n' .. BuiltinDoc.prototype .. '\n```\n\n'
   end
   md ..= BuiltinDoc.comment
   return md
end

function formatKeywordHover(Keyword, KeywordDoc)
   md = '**' .. Keyword .. '** _(Keyword)_\n\n' .. KeywordDoc.comment
   return md
end

global function resolveHoverContent(TokenInfo, Doc)
   -- Resolve hover content for a token
   -- Priority: keywords, builtins, class names, module functions, object methods/fields

   if not TokenInfo then return nil end

   token = TokenInfo.text
   context = TokenInfo.context

   -- Check for keywords
   if glDefs?.keywords?[token] then
      return formatKeywordHover(token, glDefs.keywords[token])
   end

   -- Check for built-in functions
   if glDefs?.builtins?[token] then
      return formatBuiltinHover(token, glDefs.builtins[token])
   end

   -- Handle obj.new specially
   if context is 'method_call' and TokenInfo.object is 'obj' and token is 'new' then
      if glDefs and glDefs.builtins and glDefs.builtins['obj.new'] then
         return formatBuiltinHover('obj.new', glDefs.builtins['obj.new'])
      end
   end

   -- Check for class names (standalone identifier starting with capital)
   if context is 'identifier' and token:match('^[A-Z]') then
      if glDocCache and glDocCache.classes and glDocCache.classes[token] then
         return formatClassHover(token, glDocCache.classes[token])
      end
   end

   -- Handle method or field access on an object
   if (context is 'method_call' or context is 'field_access') and TokenInfo.object then
      objName = TokenInfo.object

      -- Try to infer class type from obj.new() assignments
      typeMap = buildTypeMap(Doc)
      className = typeMap[objName]

      -- Also try the object name directly as a class (for cases like NetSocket.Connect)
      if not className and objName:match('^[A-Z]') then
         className = objName
      end

      if className and glDocCache and glDocCache.classes then
         classDoc = glDocCache.classes[className]
         if classDoc then
            if context is 'method_call' then
               -- Check for action pattern (acXxx)
               if token:match('^ac[A-Z]') then
                  actionName = token:sub(3)
                  if classDoc.actions and classDoc.actions[actionName] then
                     return formatActionHover(className, actionName, classDoc.actions[actionName])
                  end
               end

               -- Check for method pattern (mtXxx)
               if token:match('^mt[A-Z]') then
                  methodName = token:sub(3)
                  if classDoc.methods and classDoc.methods[methodName] then
                     return formatMethodHover(className, methodName, classDoc.methods[methodName])
                  end
               end

               -- Try direct method lookup
               if classDoc.methods and classDoc.methods[token] then
                  return formatMethodHover(className, token, classDoc.methods[token])
               end

               -- Also check actions without ac prefix
               if classDoc.actions and classDoc.actions[token] then
                  return formatActionHover(className, token, classDoc.actions[token])
               end
            else
               -- Field access - try various case combinations
               if classDoc.fields then
                  -- Try exact match
                  if classDoc.fields[token] then
                     return formatFieldHover(className, token, classDoc.fields[token])
                  end
                  -- Try capitalized (Fluid uses lowercase, XML uses TitleCase)
                  capitalizedToken = token:sub(1,1):upper() .. token:sub(2)
                  if classDoc.fields[capitalizedToken] then
                     return formatFieldHover(className, capitalizedToken, classDoc.fields[capitalizedToken])
                  end
               end
            end
         end
      end

      -- Try module function lookup (mSys.Sleep, mNet.AddressToStr, etc.)
      if glDefs?.modulePrefixes?[objName] then
         modName = glDefs.modulePrefixes[objName]
         if glDocCache?.modules?[modName] then
            moduleDoc = glDocCache.modules[modName]
            if moduleDoc?.functions?[token] then
               return formatModuleFunctionHover(modName, token, moduleDoc.functions[token])
            end
         end
      end
   end

   return nil
end

----------------------------------------------------------------------------------------------------------------------
-- Method Dispatch

function dispatchMethod(Self:table, Message:table, State)
   method = Message.method

   if not method then
      -- This is a response, not a request - ignore for now
      logVerbose(Self, 'Received response message (ignored)')
      return nil
   end

   handler = Self._handlers[method]

   if handler then
      logVerbose(Self, 'Dispatching method: ' .. method)
      success, result = pcall(function()
         return handler(Message, State)
      end)

      if success then
         return result
      else
         logMessage(Self, 'Handler error for ' .. method .. ': ' .. tostring(result))
         if Message.id then
            return makeErrorResponse(Message.id, LSP_ERROR.INTERNAL_ERROR, tostring(result))
         end
         return nil
      end
   else
      logWarning(Self, 'Unknown method: ' .. method)
      -- Unknown method: return error for requests, ignore notifications
      if Message.id then
         return makeErrorResponse(Message.id, LSP_ERROR.METHOD_NOT_FOUND, 'Method not found: ' .. method)
      end
      return nil
   end
end

----------------------------------------------------------------------------------------------------------------------
-- Incoming Data Handler

function processIncoming(Self:table, ClientSocket)
   state = ClientSocket._state()

   -- Initialize state on first call
   if not state.initialised then
      state.buffer             = ''
      state.phase              = 'READING_HEADER'
      state.content_length     = nil
      state.initialized        = false
      state.shutdown_requested = false
      state.should_disconnect  = false
      state.clientSocket       = ClientSocket  -- Store for sending notifications
      state.initialised        = true
      logVerbose(Self, 'New client connection initialized')
   end

   -- Read available data
   buffer = string.alloc(8192)
   err, bytes_read = ClientSocket.acRead(buffer, 8192)

   if err != ERR_Okay then
      if err != ERR_Disconnected then
         logMessage(Self, 'Read error: ' .. mSys.GetErrorMsg(err))
      end
      return
   end

   if bytes_read is 0 then return end

   -- Accumulate data
   state.buffer ..= buffer:sub(0, bytes_read)
   logVerbose(Self, 'Received ' .. bytes_read .. ' bytes, buffer now ' .. #state.buffer .. ' bytes')

   -- Process messages in a loop (may have multiple messages in buffer)
   while #state.buffer > 0 do
      if state.phase is 'READING_HEADER' then
         content_length, body_start, parse_err = parseHeader(state.buffer)

         if not content_length then
            if parse_err then
               logMessage(Self, 'Header parse error: ' .. parse_err)
               state.buffer = ''
            end
            break  -- Need more data or error occurred
         end

         state.content_length = content_length
         state.buffer = state.buffer:sub(body_start)
         state.phase = 'READING_BODY'
         logVerbose(Self, 'Header parsed, expecting ' .. content_length .. ' bytes')
      end

      if state.phase is 'READING_BODY' then
         if #state.buffer < state.content_length then
            break  -- Need more data
         end

         -- Extract the JSON body
         json_body = state.buffer:sub(0, state.content_length)
         state.buffer = state.buffer:sub(state.content_length)
         state.phase = 'READING_HEADER'

         logVerbose(Self, 'Received message: ' .. json_body:sub(0, 200))

         -- Log incoming request if logging enabled
         if Self.requestLog then
            Self.requestLog('REQUEST', json_body)
         end

         -- Parse and dispatch
         message, parse_err = parseMessage(json_body)
         if message then
            response = dispatchMethod(Self, message, state)
            sendResponse(Self, ClientSocket, response, Self.requestLog)

            -- Check if we should disconnect after exit
            if state.should_disconnect then
               logVerbose(Self, 'Disconnecting client per exit request')
               ClientSocket.acDeactivate()
               return
            end
         else
            logMessage(Self, 'Parse error: ' .. tostring(parse_err))
            -- Send parse error response if we can determine an ID
            sendResponse(Self, ClientSocket, makeErrorResponse(json.null, LSP_ERROR.PARSE_ERROR, parse_err), Self.requestLog)
         end
      end
   end
end

----------------------------------------------------------------------------------------------------------------------
-- Public API

-- Initialize the documentation system for hover support
-- DocPath: Path to the XML document folder (e.g., 'sdk:docs/xml/')
-- Returns true if successful

global function lspInitDocs(DocPath)
   DocPath ?? return false

   if not DocPath:match('[/\\]$') then -- Ensure path ends with separator
      DocPath = DocPath .. '/'
   end

   -- Load static definitions (builtins, keywords)
   defsPath = glSelf.workingPath .. 'lsp_defs.fluid'
   success, result = pcall(function()
      return loadFile(defsPath)
   end)

   if success and result then
      glDefs = result
      print('Loaded static definitions')
   else
      print('Failed to load static definitions from ' .. defsPath)
   end

   -- Try to load cached documentation
   glDocCache = loadDocCache(DocPath)

   if glDocCache then
      print('Loaded documentation cache')
   else
      -- Build cache if not found or invalid
      glDocCache = buildDocCache(DocPath)
      if glDocCache then
         saveDocCache(CACHE_PATH, glDocCache)
         print('Documentation cache built and saved')
      else
         print('Failed to build documentation cache')
      end
   end

   return glDocCache != nil
end

global function lspStart(Options)
   Options ?= {}

   self.port       = Options.port or 5007
   self.verbose    = Options.verbose or false
   self.logMessage = Options.logMessage or function(msg) print(msg) end
   self.requestLog = Options.requestLog  -- Optional request/response logging callback
   self._socket    = nil
   self._handlers  = {}

   registerCoreHandlers(self)

   logMessage(self, 'Starting Fluid LSP Server on port ' .. self.port)

   -- Create TCP server socket
   self._socket = obj.new('netsocket', {
      port = self.port,
      flags = 'SERVER|MULTI_CONNECT',
      feedback = function(Server, ClientSocket, State)
         if State is NTC_CONNECTED then
            logMessage(self, 'LSP client connected')
         elseif State is NTC_DISCONNECTED then
            logMessage(self, 'LSP client disconnected')
         end
      end,
      incoming = function(Server, ClientSocket)
         processIncoming(self, ClientSocket)
      end
   })

   logMessage(self, 'Fluid LSP Server listening on port ' .. self.port)
   if self.verbose then
      logMessage(self, 'Verbose logging enabled')
   end

   -- Public methods

   self.stop = function()
      if self._socket then
         logMessage(self, 'Stopping LSP server')
         self._socket = nil
         collectgarbage()
      end
   end

   self.registerHandler = function(Method, Handler)
      assert(type(Handler) is 'function', 'Handler must be a function')
      self._handlers[Method] = Handler
      logVerbose(self, 'Registered handler for: ' .. Method)
   end

   return self
end
