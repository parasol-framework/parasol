-- Fluid Language Server Protocol (LSP) Server Library
--
-- Provides a TCP-based LSP server for IDE integration with Fluid scripts.
-- Implements the JSON-RPC 2.0 protocol with LSP wire format (Content-Length framing).
--
-- Usage:
--    lsplib = require 'dev/lsp'
--    server = lsplib.start({ port = 5007, verbose = true })
--    processing.sleep()
--
-- The server supports handler registration for extending LSP functionality:
--    server.registerHandler('textDocument/hover', function(msg, state) ... end)

   include 'network'
   json = require('json')

   lsp = { } -- Library export

   glTime = obj.new('time')

   -- Document storage for open files.  URI indexed
   glDocuments = { }

   -- Token cache for delta semantic tokens.  URI indexed
   -- Structure: { [uri] = { resultId = number, data = { ... } } }
   glTokenCache = { }
   glNextResultId = 1

----------------------------------------------------------------------------------------------------------------------
-- Semantic Token Types and Modifiers (LSP standard)

-- Token types - order matters, index is used in the protocol

TOKEN_TYPES = array<string> {
   'keyword',        -- 0: if, while, for, etc.
   'operator',       -- 1: and, or, not, is
   'variable',       -- 2: regular variables
   'function',       -- 3: function names
   'string',         -- 4: string literals
   'number',         -- 5: numeric literals
   'comment',        -- 6: comments
   'type',           -- 7: type names
   'parameter',      -- 8: function parameters
   'property',       -- 9: object properties
   'namespace',      -- 10: module/namespace
   'class',          -- 11: class names
   'macro'           -- 12: constants like ERR_Okay
}

-- Token modifiers (bitfield)
TOKEN_MODIFIERS = array<string> {
   'declaration',    -- 0: variable/function declaration
   'definition',     -- 1: definition site
   'readonly',       -- 2: constants
   'static',         -- 3: static members
   'deprecated',     -- 4: deprecated items
   'modification',   -- 5: modified variable
   'documentation',  -- 6: documentation strings
   'defaultLibrary'  -- 7: built-in functions
}

-- Fluid reserved keywords
FLUID_KEYWORDS = {
   -- Control flow
   ['if'] = true, ['then'] = true, ['else'] = true, ['elseif'] = true,
   ['for'] = true, ['in'] = true, ['while'] = true, ['do'] = true,
   ['repeat'] = true, ['until'] = true, ['break'] = true, ['continue'] = true,
   ['return'] = true, ['end'] = true,

   -- Pattern matching
   ['choose'] = true, ['from'] = true, ['when'] = true,

   -- Declarations
   ['function'] = true, ['local'] = true, ['global'] = true, ['thunk'] = true,

   -- Special
   ['defer'] = true, ['catch'] = true, ['raise'] = true, ['check'] = true
}

-- Logical/comparison operators (highlighted as operators)
FLUID_OPERATORS = {
   ['and'] = true, ['or'] = true, ['not'] = true, ['is'] = true
}

-- Built-in constants
FLUID_CONSTANTS = {
   ['true'] = true, ['false'] = true, ['nil'] = true
}

-- Built-in functions (default library)
FLUID_BUILTINS = {
   -- Output
   ['print'] = true, ['msg'] = true, ['error'] = true, ['assert'] = true,

   -- Type conversion/introspection
   ['type'] = true, ['tonumber'] = true, ['tostring'] = true,

   -- Iteration
   ['pairs'] = true, ['ipairs'] = true, ['next'] = true, ['values'] = true,

   -- Result handling
   ['unpack'] = true,

   -- Protected calls
   ['pcall'] = true, ['xpcall'] = true,

   -- Metatable access
   ['setmetatable'] = true, ['getmetatable'] = true,
   ['rawget'] = true, ['rawset'] = true, ['rawequal'] = true,

   -- Script/module loading
   ['collectgarbage'] = true, ['require'] = true, ['include'] = true,
   ['loadFile'] = true, ['load'] = true, ['exec'] = true,

   -- Script parameters
   ['arg'] = true,

   -- Deferred expressions
   ['resolve'] = true,

   -- Range constructor
   ['range'] = true,

   -- Events
   ['subscribeEvent'] = true, ['unsubscribeEvent'] = true,

   -- Structures
   ['MAKESTRUCT'] = true
}

-- Parasol modules/namespaces
FLUID_MODULES = {
   -- Core interfaces
   ['obj'] = true, ['struct'] = true, ['array'] = true, ['regex'] = true,
   ['mod'] = true, ['thread'] = true, ['processing'] = true,

   -- Parasol API modules (loaded via mod.load())
   ['mSys'] = true, ['mVec'] = true, ['mGfx'] = true,
   ['mAudio'] = true, ['mFont'] = true, ['mNet'] = true, ['mXML'] = true,

   -- Standard libraries
   ['string'] = true, ['table'] = true, ['math'] = true, ['bit'] = true,
   ['io'] = true, ['debug'] = true,

   -- Fluid script libraries
   ['json'] = true, ['gui'] = true, ['file'] = true
}

----------------------------------------------------------------------------------------------------------------------
-- Utility Functions

function timestamp():str
   glTime.acQuery()
   return string.format('%04d-%02d-%02d %02d:%02d:%02d',
      glTime.year, glTime.month, glTime.day, glTime.hour, glTime.minute, glTime.second)
end

function logMessage(Self:table, Message:str)
   Self?.logMessage('[' .. timestamp() .. '] ' .. Message)
end

function logVerbose(Self:table, Message:str)
   if Self.verbose then
      Self?.logMessage('[' .. timestamp() .. '] [DEBUG] ' .. Message)
   end
end

function logWarning(Self:table, Message:str)
   Self?.logMessage('[' .. timestamp() .. '] [WARN] ' .. Message)
end

----------------------------------------------------------------------------------------------------------------------
-- LSP Wire Protocol Parsing

-- Parse the Content-Length header from the buffer
-- Returns: content_length, body_start_offset, error_message
-- If incomplete (need more data): nil, nil, nil
-- If error: nil, nil, error_string
-- If success: content_length, body_start_offset, nil

function parseHeader(Buffer:str):<str,num,str>
   header_end = Buffer:find('\r\n\r\n')
   header_end ?? return nil, nil, nil  -- Need more data
   header_section = Buffer:sub(0, header_end)
   content_length = nil

   for line in header_section:gmatch('[^\r\n]+') do
      name, value = line:match('([^:]+):%s*(.+)')
      if name and name:lower() is 'content-length' then
         content_length = tonumber(value)
         break
      end
   end

   content_length ?? return nil, nil, 'Missing Content-Length header'
   return content_length, header_end + 4, nil  -- +4 for \r\n\r\n
end

----------------------------------------------------------------------------------------------------------------------
-- Parse a JSON-RPC 2.0 message

function parseMessage(JsonBody)
   local success, msg = pcall(function()
      return json.decode(JsonBody)
   end)

   success ?? return nil, 'JSON parse error: ' .. tostring(msg)

   if msg.jsonrpc != '2.0' then
      return nil, 'Invalid JSON-RPC version: ' .. tostring(msg.jsonrpc)
   end

   return msg, nil
end

----------------------------------------------------------------------------------------------------------------------
-- Response Formatting

function formatResponse(ResponseTable:table):str
   body = json.encode(ResponseTable)
   return 'Content-Length: ' .. #body .. '\r\n\r\n' .. body
end

function sendResponse(Self, ClientSocket, ResponseTable, RequestLog)
   ResponseTable ?? return -- Notifications don't get responses

   formatted = formatResponse(ResponseTable)
   err = ClientSocket.acWrite(formatted)
   if err != ERR_Okay then
      logMessage(Self, 'Failed to send response: ' .. mSys.GetErrorMsg(err))
   else
      logVerbose(Self, 'Sent response: ' .. formatted:sub(0, 200))

      -- Log outgoing response if logging enabled
      if RequestLog then
         RequestLog('RESPONSE', formatted)
      end
   end
end

----------------------------------------------------------------------------------------------------------------------
-- Text Edit Helper

-- Convert line/character position to byte offset in document
function positionToOffset(Content, Line, Character)
   offset = 0
   current_line = 0

   while current_line < Line and offset < #Content do
      c = Content:sub(offset, offset + 1)
      if c is '\n' then
         current_line++
      end
      offset++
   end

   -- Add character offset within the line
   return offset + Character
end

-- Apply a text edit to document content
function applyTextEdit(Content, Range, NewText)
   start_offset = positionToOffset(Content, Range.start.line, Range.start.character)
   end_offset = positionToOffset(Content, Range['end'].line, Range['end'].character)

   -- Build new content: before + new text + after
   before = Content:sub(0, start_offset)
   after = Content:sub(end_offset)

   return before .. NewText .. after
end

----------------------------------------------------------------------------------------------------------------------
-- LSP Error Codes

LSP_ERROR = {
   PARSE_ERROR      = -32700,
   INVALID_REQUEST  = -32600,
   METHOD_NOT_FOUND = -32601,
   INVALID_PARAMS   = -32602,
   INTERNAL_ERROR   = -32603
}

function makeErrorResponse(Id:num, Code:num, Message:str):table
   return {
      jsonrpc = '2.0',
      id = Id,
      error = {
         code = Code,
         message = Message
      }
   }
end

----------------------------------------------------------------------------------------------------------------------
-- Semantic Token Encoder

-- Tokenize a Fluid source file and return semantic tokens
-- Returns array of tokens: { line, startChar, length, tokenType, tokenModifiers }

function tokenizeFluid(Source:str):array
   tokens = array<table>
   line = 0
   col = 0
   pos = 0
   len = #Source

   -- Helper to add a token (skips zero-length tokens)
   function addToken(TokenLine, TokenCol, TokenLen, TokenType, TokenMod)
      if TokenLen <= 0 then return end  -- Skip invalid tokens
      tokens:push({
         line   = TokenLine,
         char   = TokenCol,
         length = TokenLen,
         type   = TokenType,
         modifiers = TokenMod or 0
      })
   end

   -- Skip whitespace and track position
   function skipWhitespace()
      while pos < len do
         c = Source:sub(pos, pos + 1)
         if c is ' ' or c is '\t' then
            col++
            pos++
         elseif c is '\n' then
            line++
            col = 0
            pos++
         elseif c is '\r' then
            pos++
            if pos < len and Source:sub(pos, pos + 1) is '\n' then
               pos++
            end
            line++
            col = 0
         else
            break
         end
      end
   end

   -- Check if character is identifier start
   function isIdentStart(C)
      return (C >= 'a' and C <= 'z') or (C >= 'A' and C <= 'Z') or C is '_'
   end

   -- Check if character is identifier continuation
   function isIdentChar(C)
      return isIdentStart(C) or (C >= '0' and C <= '9')
   end

   -- Check if character is digit
   function isDigit(C)
      return C >= '0' and C <= '9'
   end

   -- Main tokenization loop
   while pos < len do
      skipWhitespace()
      if pos >= len then break end

      c = Source:sub(pos, pos + 1)
      start_col = col
      start_pos = pos

      -- Line comment: --
      if c is '-' and pos + 1 < len and Source:sub(pos + 1, pos + 2) is '-' then
         comment_start = col

         -- Check for block comment --[[
         if pos + 3 < len and Source:sub(pos + 2, pos + 4) is '[[' then
            pos += 4
            col += 4
            -- Find closing ]]
            while pos < len do
               if Source:sub(pos, pos + 2) is ']]' then
                  pos += 2
                  col += 2
                  break
               elseif Source:sub(pos, pos + 1) is '\n' then
                  -- Only add token if there's content on this line
                  if col > comment_start then
                     addToken(line, comment_start, col - comment_start, 6, 0)  -- comment
                  end
                  line++
                  col = 0
                  pos++
                  comment_start = 0
               else
                  pos++
                  col++
               end
            end
            -- Add final line of block comment if there's content
            if col > comment_start then
               addToken(line, comment_start, col - comment_start, 6, 0)  -- comment
            end
         else
            -- Line comment - find end of line
            while pos < len and Source:sub(pos, pos + 1) != '\n' do
               pos++
               col++
            end
            addToken(line, comment_start, col - comment_start, 6, 0)  -- comment
         end

      -- String literals
      elseif c is '"' or c is "'" then
         quote = c
         str_start = col
         pos++
         col++
         while pos < len do
            sc = Source:sub(pos, pos + 1)
            if sc is quote then
               pos++
               col++
               break
            elseif sc is '\\' then
               pos += 2
               col += 2
            elseif sc is '\n' then
               break  -- Unterminated string
            else
               pos++
               col++
            end
         end
         addToken(line, str_start, col - str_start, 4, 0)  -- string

      -- Multiline string [[
      elseif c is '[' and pos + 1 < len and Source:sub(pos + 1, pos + 2) is '[' then
         str_start_line = line
         str_start_col = col
         pos += 2
         col += 2
         segment_start = col
         while pos < len do
            if Source:sub(pos, pos + 2) is ']]' then
               if col > segment_start or line is str_start_line then
                  addToken(line, (line is str_start_line) and str_start_col or 0,
                     (line is str_start_line) and (col - str_start_col + 2) or (col + 2), 4, 0)
               end
               pos += 2
               col += 2
               break
            elseif Source:sub(pos, pos + 1) is '\n' then
               if line is str_start_line then
                  addToken(line, str_start_col, col - str_start_col, 4, 0)
               else
                  addToken(line, 0, col, 4, 0)
               end
               line++
               col = 0
               pos++
               segment_start = 0
            else
               pos++
               col++
            end
         end

      -- Numbers
      elseif isDigit(c) or (c is '.' and pos + 1 < len and isDigit(Source:sub(pos + 1, pos + 2))) then
         num_start = col
         -- Hex number
         if c is '0' and pos + 1 < len and (Source:sub(pos + 1, pos + 2) is 'x' or Source:sub(pos + 1, pos + 2) is 'X') then
            pos += 2
            col += 2
            while pos < len do
               nc = Source:sub(pos, pos + 1)
               if isDigit(nc) or (nc >= 'a' and nc <= 'f') or (nc >= 'A' and nc <= 'F') then
                  pos++
                  col++
               else
                  break
               end
            end
         else
            -- Decimal number
            while pos < len and isDigit(Source:sub(pos, pos + 1)) do
               pos++
               col++
            end
            -- Decimal part
            if pos < len and Source:sub(pos, pos + 1) is '.' then
               pos++
               col++
               while pos < len and isDigit(Source:sub(pos, pos + 1)) do
                  pos++
                  col++
               end
            end
            -- Exponent
            if pos < len and (Source:sub(pos, pos + 1) is 'e' or Source:sub(pos, pos + 1) is 'E') then
               pos++
               col++
               if pos < len and (Source:sub(pos, pos + 1) is '+' or Source:sub(pos, pos + 1) is '-') then
                  pos++
                  col++
               end
               while pos < len and isDigit(Source:sub(pos, pos + 1)) do
                  pos++
                  col++
               end
            end
         end
         addToken(line, num_start, col - num_start, 5, 0)  -- number

      -- Identifiers and keywords
      elseif isIdentStart(c) then
         ident_start = col
         while pos < len and isIdentChar(Source:sub(pos, pos + 1)) do
            pos++
            col++
         end
         ident = Source:sub(start_pos, pos)
         ident_len = col - ident_start

         if FLUID_KEYWORDS[ident] then
            addToken(line, ident_start, ident_len, 0, 0)  -- keyword
         elseif FLUID_OPERATORS[ident] then
            addToken(line, ident_start, ident_len, 1, 0)  -- operator
         elseif FLUID_CONSTANTS[ident] then
            addToken(line, ident_start, ident_len, 12, 4)  -- macro + readonly
         elseif FLUID_BUILTINS[ident] then
            addToken(line, ident_start, ident_len, 3, 128)  -- function + defaultLibrary
         elseif FLUID_MODULES[ident] then
            addToken(line, ident_start, ident_len, 10, 0)  -- namespace
         elseif ident:match('^ERR_') then
            addToken(line, ident_start, ident_len, 12, 4)  -- macro + readonly (error constants)
         elseif ident:match('^gl[A-Z]') then
            addToken(line, ident_start, ident_len, 2, 8)  -- variable + static (global)
         elseif ident:match('^[A-Z]') and ident:match('^[A-Z_]+$') then
            addToken(line, ident_start, ident_len, 12, 4)  -- macro + readonly (CONSTANTS)
         else
            -- Check if it's a function call (followed by parenthesis)
            -- Save all position state since skipWhitespace may cross newlines
            save_pos = pos
            save_col = col
            save_line = line
            skipWhitespace()
            if pos < len and Source:sub(pos, pos + 1) is '(' then
               addToken(save_line, ident_start, ident_len, 3, 0)  -- function
            end
            -- Restore position (we don't consume the paren)
            pos = save_pos
            col = save_col
            line = save_line
         end

      -- Symbolic operators (multi-character first, then single-character)
      elseif c is '?' then
         op_start = col
         if pos + 2 < len and Source:sub(pos + 1, pos + 3) is '?=' then
            -- ??= if-empty assignment
            addToken(line, op_start, 3, 1, 0)
            pos += 3
            col += 3
         elseif pos + 1 < len and Source:sub(pos + 1, pos + 2) is '?' then
            -- ?? if-empty operator
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         elseif pos + 1 < len and Source:sub(pos + 1, pos + 2) is '=' then
            -- ?= if-nil assignment
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         elseif pos + 1 < len and Source:sub(pos + 1, pos + 2) is '.' then
            -- ?. safe navigation
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         elseif pos + 1 < len and Source:sub(pos + 1, pos + 2) is '[' then
            -- ?[ safe index
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- ? ternary condition
            addToken(line, op_start, 1, 1, 0)
            pos++
            col++
         end

      elseif c is '|' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '>' then
            -- |> pipe operator
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- | bitwise OR
            addToken(line, op_start, 1, 1, 0)
            pos++
            col++
         end

      elseif c is '=' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '>' then
            -- => arrow function
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- = assignment (skip, not highlighted as operator)
            pos++
            col++
         end

      elseif c is ':' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '>' then
            -- :> ternary else
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- : type annotation or method call (skip)
            pos++
            col++
         end

      elseif c is '.' then
         op_start = col
         if pos + 2 < len and Source:sub(pos + 1, pos + 3) is '.=' then
            -- ..= concatenation assignment
            addToken(line, op_start, 3, 1, 0)
            pos += 3
            col += 3
         elseif pos + 2 < len and Source:sub(pos + 1, pos + 3) is '..' then
            -- ... varargs or inclusive range
            addToken(line, op_start, 3, 1, 0)
            pos += 3
            col += 3
         elseif pos + 1 < len and Source:sub(pos + 1, pos + 2) is '.' then
            -- .. concatenation or exclusive range
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- . field access (skip)
            pos++
            col++
         end

      elseif c is '+' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '+' then
            -- ++ increment
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         elseif pos + 1 < len and Source:sub(pos + 1, pos + 2) is '=' then
            -- += compound assignment
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- + addition
            addToken(line, op_start, 1, 1, 0)
            pos++
            col++
         end

      elseif c is '-' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '=' then
            -- -= compound assignment
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- - subtraction/negation
            addToken(line, op_start, 1, 1, 0)
            pos++
            col++
         end

      elseif c is '*' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '=' then
            -- *= compound assignment
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- * multiplication
            addToken(line, op_start, 1, 1, 0)
            pos++
            col++
         end

      elseif c is '/' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '=' then
            -- /= compound assignment
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- / division
            addToken(line, op_start, 1, 1, 0)
            pos++
            col++
         end

      elseif c is '%' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '=' then
            -- %= compound assignment
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- % modulo
            addToken(line, op_start, 1, 1, 0)
            pos++
            col++
         end

      elseif c is '<' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '<' then
            -- << left shift
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         elseif pos + 1 < len and Source:sub(pos + 1, pos + 2) is '=' then
            -- <= less than or equal
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- < less than
            addToken(line, op_start, 1, 1, 0)
            pos++
            col++
         end

      elseif c is '>' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '>' then
            -- >> right shift
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         elseif pos + 1 < len and Source:sub(pos + 1, pos + 2) is '=' then
            -- >= greater than or equal
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- > greater than
            addToken(line, op_start, 1, 1, 0)
            pos++
            col++
         end

      elseif c is '!' then
         op_start = col
         if pos + 1 < len and Source:sub(pos + 1, pos + 2) is '=' then
            -- != not equal
            addToken(line, op_start, 2, 1, 0)
            pos += 2
            col += 2
         else
            -- ! (used in flags like '!READ')
            pos++
            col++
         end

      elseif c is '&' then
         -- & bitwise AND
         addToken(line, col, 1, 1, 0)
         pos++
         col++

      elseif c is '~' then
         -- ~ bitwise NOT
         addToken(line, col, 1, 1, 0)
         pos++
         col++

      elseif c is '^' then
         -- ^ exponentiation
         addToken(line, col, 1, 1, 0)
         pos++
         col++

      elseif c is '#' then
         -- # length operator
         addToken(line, col, 1, 1, 0)
         pos++
         col++

      else
         -- Skip other characters (punctuation, brackets, etc.)
         pos++
         col++
      end
   end

   return tokens
end

----------------------------------------------------------------------------------------------------------------------
-- Encode tokens into LSP semantic tokens format (delta-encoded integers)

function encodeSemanticTokens(Tokens:array):array
   data = array<int>
   prev_line = 0
   prev_char = 0

   for tok in values(Tokens) do
      delta_line = tok.line - prev_line
      delta_char = (delta_line is 0) and (tok.char - prev_char) or tok.char

      data:push(delta_line)
      data:push(delta_char)
      data:push(tok.length)
      data:push(tok.type)
      data:push(tok.modifiers)

      prev_line = tok.line
      prev_char = tok.char
   end

   return data
end

----------------------------------------------------------------------------------------------------------------------
-- Compute semantic token edits between old and new data arrays
-- Returns array of SemanticTokensEdit: { start, deleteCount, data? }

function computeTokenEdits(OldData:array, NewData:array):array
   old_len = #OldData
   new_len = #NewData

   -- Find common prefix (in groups of 5 integers = 1 token)
   prefix_tokens = 0
   max_prefix = math.min(old_len, new_len) / 5
   while prefix_tokens < max_prefix do
      idx = prefix_tokens * 5
      match = true
      for i = 0, 4 do
         if OldData[idx + i] != NewData[idx + i] then
            match = false
            break
         end
      end
      if not match then break end
      prefix_tokens++
   end

   -- Find common suffix (in groups of 5 integers = 1 token)
   suffix_tokens = 0
   old_suffix_start = old_len
   new_suffix_start = new_len
   max_suffix = math.min((old_len / 5) - prefix_tokens, (new_len / 5) - prefix_tokens)

   while suffix_tokens < max_suffix do
      old_idx = old_len - (suffix_tokens + 1) * 5
      new_idx = new_len - (suffix_tokens + 1) * 5
      match = true
      for i = 0, 4 do
         if OldData[old_idx + i] != NewData[new_idx + i] then
            match = false
            break
         end
      end
      if not match then break end
      suffix_tokens++
   end

   -- Calculate the range that differs
   prefix_ints = prefix_tokens * 5
   suffix_ints = suffix_tokens * 5

   delete_start = prefix_ints
   delete_count = old_len - prefix_ints - suffix_ints
   insert_count = new_len - prefix_ints - suffix_ints

   -- If nothing changed, return empty edits
   if delete_count is 0 and insert_count is 0 then
      return array<table>
   end

   -- Build the edit
   edit = {
      start = delete_start,
      deleteCount = delete_count
   }

   -- Include new data if we're inserting anything
   if insert_count > 0 then
      edit.data = array<int>
      for i = prefix_ints, prefix_ints + insert_count - 1 do
         edit.data:push(NewData[i])
      end
   end

   return array<table> { edit }
end

----------------------------------------------------------------------------------------------------------------------
-- Core LSP Handlers

function registerCoreHandlers(Self)
   -- initialize: Client initiates handshake
   Self._handlers['initialize'] = function(Msg, State)
      State.initialized = true
      logMessage(Self, 'LSP initialize request received')

      return {
         jsonrpc = '2.0',
         id = Msg.id,
         result = {
            capabilities = {
               -- Incremental sync: client sends only changed portions
               textDocumentSync = {
                  openClose = true,
                  change = 2  -- Incremental sync
               },
               -- Semantic tokens for syntax highlighting
               semanticTokensProvider = {
                  legend = {
                     tokenTypes = TOKEN_TYPES,
                     tokenModifiers = TOKEN_MODIFIERS
                  },
                  full = {
                     delta = true  -- Support delta updates for efficiency
                  },
                  range = false
               }
            },
            serverInfo = {
               name = 'Fluid LSP Server',
               version = '0.1.0'
            }
         }
      }
   end

   -- initialized: Client confirms handshake complete (notification, no response)
   Self._handlers['initialized'] = function(Msg, State)
      logMessage(Self, 'LSP initialized notification received - handshake complete')
      return nil
   end

   -- shutdown: Client requests shutdown preparation
   Self._handlers['shutdown'] = function(Msg, State)
      State.shutdown_requested = true
      logMessage(Self, 'LSP shutdown request received')

      return {
         jsonrpc = '2.0',
         id = Msg.id,
         result = json.null
      }
   end

   -- exit: Client requests termination (notification)
   Self._handlers['exit'] = function(Msg, State)
      if State.shutdown_requested then
         logMessage(Self, 'LSP exit notification - clean shutdown')
      else
         logMessage(Self, 'LSP exit notification - unexpected (no prior shutdown)')
      end
      State.should_disconnect = true
      return nil
   end

   --------------------------------------------------------------------------
   -- Document Synchronization

   -- textDocument/didOpen: Client opened a document
   Self._handlers['textDocument/didOpen'] = function(Msg, State)
      doc = Msg.params.textDocument
      glDocuments[doc.uri] = {
         uri = doc.uri,
         languageId = doc.languageId,
         version = doc.version,
         content = doc.text
      }
      logMessage(Self, 'Document opened: ' .. doc.uri)
      return nil  -- Notification, no response
   end

   -- textDocument/didChange: Document content changed
   Self._handlers['textDocument/didChange'] = function(Msg, State)
      uri = Msg.params.textDocument.uri
      version = Msg.params.textDocument.version

      if glDocuments[uri] then
         for _, change in ipairs(Msg.params.contentChanges) do
            if change.range then
               -- Incremental sync: apply text edit at range
               glDocuments[uri].content = applyTextEdit(
                  glDocuments[uri].content,
                  change.range,
                  change.text
               )
            else
               -- Full sync fallback: replace entire content
               glDocuments[uri].content = change.text
            end
         end
         glDocuments[uri].version = version
         logVerbose(Self, 'Document updated: ' .. uri .. ' (version ' .. version .. ')')
      end
      return nil  -- Notification, no response
   end

   -- textDocument/didClose: Client closed a document
   Self._handlers['textDocument/didClose'] = function(Msg, State)
      uri = Msg.params.textDocument.uri
      glDocuments[uri] = nil
      glTokenCache[uri] = nil  -- Clear token cache to free memory
      logMessage(Self, 'Document closed: ' .. uri)
      return nil  -- Notification, no response
   end

   --------------------------------------------------------------------------
   -- Semantic Tokens

   -- textDocument/semanticTokens/full: Return all semantic tokens for a document

   Self._handlers['textDocument/semanticTokens/full'] = function(Msg, State)
      uri = Msg.params.textDocument.uri
      doc = glDocuments[uri]

      if not doc then
         logMessage(Self, 'Semantic tokens requested for unknown document: ' .. uri)
         return {
            jsonrpc = '2.0',
            id = Msg.id,
            result = { data = array<int> }
         }
      end

      logVerbose(Self, 'Computing semantic tokens for: ' .. uri)

      tokens = tokenizeFluid(doc.content)
      encoded = encodeSemanticTokens(tokens)

      -- Generate resultId and cache for delta requests
      result_id = tostring(glNextResultId)
      glNextResultId++

      glTokenCache[uri] = {
         resultId = result_id,
         data = encoded
      }

      logVerbose(Self, 'Returning ' .. #tokens .. ' tokens (' .. #encoded .. ' integers), resultId=' .. result_id)

      return {
         jsonrpc = '2.0',
         id = Msg.id,
         result = {
            resultId = result_id,
            data = encoded
         }
      }
   end

   -- textDocument/semanticTokens/full/delta: Return only changed semantic tokens
   Self._handlers['textDocument/semanticTokens/full/delta'] = function(Msg, State)
      uri = Msg.params.textDocument.uri
      previous_result_id = Msg.params.previousResultId
      doc = glDocuments[uri]

      if not doc then
         logMessage(Self, 'Semantic tokens delta requested for unknown document: ' .. uri)
         return {
            jsonrpc = '2.0',
            id = Msg.id,
            result = { data = array<int> }
         }
      end

      -- Check if we have the previous result cached
      cached = glTokenCache[uri]
      if not cached or cached.resultId != previous_result_id then
         -- Can't compute delta, return full tokens
         logWarning(Self, 'Cannot compute delta (no cache or resultId mismatch), returning full tokens')

         tokens = tokenizeFluid(doc.content)
         encoded = encodeSemanticTokens(tokens)

         result_id = tostring(glNextResultId)
         glNextResultId++

         glTokenCache[uri] = {
            resultId = result_id,
            data = encoded
         }

         return {
            jsonrpc = '2.0',
            id = Msg.id,
            result = {
               resultId = result_id,
               data = encoded
            }
         }
      end

      logVerbose(Self, 'Computing semantic tokens delta for: ' .. uri)

      -- Compute new tokens
      tokens = tokenizeFluid(doc.content)
      new_encoded = encodeSemanticTokens(tokens)

      -- Compute delta between old and new
      edits = computeTokenEdits(cached.data, new_encoded)

      -- Generate new resultId and update cache
      result_id = tostring(glNextResultId)
      glNextResultId++

      glTokenCache[uri] = {
         resultId = result_id,
         data = new_encoded
      }

      -- Calculate edit size for logging
      edit_size = 0
      for edit in values(edits) do
         edit_size += (edit.data and #edit.data or 0)
      end

      logVerbose(Self, 'Returning ' .. #edits .. ' edits (' .. edit_size .. ' integers vs ' .. #new_encoded .. ' full), resultId=' .. result_id)

      return {
         jsonrpc = '2.0',
         id = Msg.id,
         result = {
            resultId = result_id,
            edits = edits
         }
      }
   end
end

----------------------------------------------------------------------------------------------------------------------
-- Method Dispatch

function dispatchMethod(Self, Message, State)
   method = Message.method

   if not method then
      -- This is a response, not a request - ignore for now
      logVerbose(Self, 'Received response message (ignored)')
      return nil
   end

   handler = Self._handlers[method]

   if handler then
      logVerbose(Self, 'Dispatching method: ' .. method)
      success, result = pcall(function()
         return handler(Message, State)
      end)

      if success then
         return result
      else
         logMessage(Self, 'Handler error for ' .. method .. ': ' .. tostring(result))
         if Message.id then
            return makeErrorResponse(Message.id, LSP_ERROR.INTERNAL_ERROR, tostring(result))
         end
         return nil
      end
   else
      logVerbose(Self, 'Unknown method: ' .. method)
      -- Unknown method: return error for requests, ignore notifications
      if Message.id then
         return makeErrorResponse(Message.id, LSP_ERROR.METHOD_NOT_FOUND, 'Method not found: ' .. method)
      end
      return nil
   end
end

----------------------------------------------------------------------------------------------------------------------
-- Incoming Data Handler

function processIncoming(Self, ClientSocket)
   state = ClientSocket._state()

   -- Initialize state on first call
   if not state.initialised then
      state.buffer             = ''
      state.phase              = 'READING_HEADER'
      state.content_length     = nil
      state.initialized        = false
      state.shutdown_requested = false
      state.should_disconnect  = false
      state.initialised        = true
      logVerbose(Self, 'New client connection initialized')
   end

   -- Read available data
   buffer = string.alloc(8192)
   err, bytes_read = ClientSocket.acRead(buffer, 8192)

   if err != ERR_Okay then
      if err != ERR_Disconnected then
         logMessage(Self, 'Read error: ' .. mSys.GetErrorMsg(err))
      end
      return
   end

   if bytes_read is 0 then return end

   -- Accumulate data
   state.buffer ..= buffer:sub(0, bytes_read)
   logVerbose(Self, 'Received ' .. bytes_read .. ' bytes, buffer now ' .. #state.buffer .. ' bytes')

   -- Process messages in a loop (may have multiple messages in buffer)
   while #state.buffer > 0 do
      if state.phase is 'READING_HEADER' then
         content_length, body_start, parse_err = parseHeader(state.buffer)

         if not content_length then
            if parse_err then
               logMessage(Self, 'Header parse error: ' .. parse_err)
               state.buffer = ''
            end
            break  -- Need more data or error occurred
         end

         state.content_length = content_length
         state.buffer = state.buffer:sub(body_start)
         state.phase = 'READING_BODY'
         logVerbose(Self, 'Header parsed, expecting ' .. content_length .. ' bytes')
      end

      if state.phase is 'READING_BODY' then
         if #state.buffer < state.content_length then
            break  -- Need more data
         end

         -- Extract the JSON body
         json_body = state.buffer:sub(0, state.content_length)
         state.buffer = state.buffer:sub(state.content_length)
         state.phase = 'READING_HEADER'

         logVerbose(Self, 'Received message: ' .. json_body:sub(0, 200))

         -- Log incoming request if logging enabled
         if Self.requestLog then
            Self.requestLog('REQUEST', json_body)
         end

         -- Parse and dispatch
         message, parse_err = parseMessage(json_body)
         if message then
            response = dispatchMethod(Self, message, state)
            sendResponse(Self, ClientSocket, response, Self.requestLog)

            -- Check if we should disconnect after exit
            if state.should_disconnect then
               logVerbose(Self, 'Disconnecting client per exit request')
               ClientSocket.acDeactivate()
               return
            end
         else
            logMessage(Self, 'Parse error: ' .. tostring(parse_err))
            -- Send parse error response if we can determine an ID
            sendResponse(Self, ClientSocket, makeErrorResponse(json.null, LSP_ERROR.PARSE_ERROR, parse_err), Self.requestLog)
         end
      end
   end
end

----------------------------------------------------------------------------------------------------------------------
-- Public API

lsp.start = function(Options)
   Options = Options or {}

   self = {
      port = Options.port or 5007,
      verbose = Options.verbose or false,
      logMessage = Options.logMessage or function(msg) print(msg) end,
      requestLog = Options.requestLog,  -- Optional request/response logging callback
      _socket = nil,
      _handlers = {}
   }

   -- Register core LSP handlers
   registerCoreHandlers(self)

   logMessage(self, 'Starting Fluid LSP Server on port ' .. self.port)

   -- Create TCP server socket
   self._socket = obj.new('netsocket', {
      port = self.port,
      flags = 'SERVER|MULTI_CONNECT',
      feedback = function(Server, ClientSocket, State)
         if State is NTC_CONNECTED then
            logMessage(self, 'LSP client connected')
         elseif State is NTC_DISCONNECTED then
            logMessage(self, 'LSP client disconnected')
         end
      end,
      incoming = function(Server, ClientSocket)
         processIncoming(self, ClientSocket)
      end
   })

   if not self._socket then
      error('Failed to create LSP server socket on port ' .. self.port)
   end

   logMessage(self, 'Fluid LSP Server listening on port ' .. self.port)
   if self.verbose then
      logMessage(self, 'Verbose logging enabled')
   end

   -- Public methods

   self.stop = function()
      if self._socket then
         logMessage(self, 'Stopping LSP server')
         self._socket = nil
         collectgarbage()
      end
   end

   self.registerHandler = function(Method, Handler)
      if type(Handler) != 'function' then
         error('Handler must be a function')
      end
      self._handlers[Method] = Handler
      logVerbose(self, 'Registered handler for: ' .. Method)
   end

   return self
end

   return lsp
